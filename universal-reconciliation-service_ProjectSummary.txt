===== Project Summary =====
Project Name: universal-reconciliation-service
Generation Date: 2025-09-05 01:24:19
Generated By: PowerShell Script
Total Source Code Words: 6194
Total Dataset/Text Words: 16376
Description: A comprehensive summary of the project's structure, source code, and data files, designed for secure LLM context submission.
===========================

===== Directory Structure =====
all_code_dump.txt
netlify.toml
package.json
project-audit-report.txt
project_analysis_script.ps1
README.md
test_reconciliation.js
test_reconciliation.py
universal-reconciliation-service_ProjectSummary.txt
.netlify\state.json
analysis\performance_analysis.py
data\sample.json
data\sample.txt
dataset\development\dev-famous-scientists.json
dataset\development\dev-landmarks.json
dataset\development\dev-major-cities.json
dataset\development\dev-popular-movies.json
dataset\development\dev-tech-companies.json
dataset\production\prod-ambiguous-entities.json
dataset\production\prod-financial-instruments.json
dataset\production\prod-historical-events.json
dataset\production\prod-legal-precedents.json
dataset\production\prod-medical-diagnoses.json
dataset\production\prod-musical-artists.json
dataset\production\prod-professional-titles.json
dataset\production\prod-scientific-terms.json
dataset\production\prod-sports-teams.json
dataset\special\special-100-entries.json
netlify\functions\api.js
netlify\functions\api.js.bak
netlify\functions\extend-propose.js
netlify\functions\extend.js
netlify\functions\metadata.js
netlify\functions\preview.js
netlify\functions\reconcile.js
netlify\functions\stream-chunk.js
netlify\functions\suggest-entity.js
netlify\functions\suggest-property.js
netlify\functions\suggest-type.js
netlify\functions\utils.js
public\index.html
scripts\dataset_generator.py
src\api.js
src\swagger.js
src\utils.js
src\routes\extend-propose.js
src\routes\extend.js
src\routes\metadata.js
src\routes\preview.js
src\routes\stream-chunk.js
src\routes\suggest-property.js
tests\accuracy.test.js
tests\performance.test.js
tests\stream.test.js


===== Source Code Files =====

--- File: test_reconciliation.py ---
Words: 451
import os
import json
import requests
from typing import Dict, List, Any

# --- Configuration ---
# Set the base URL for your reconciliation service here.
# NOTE: This is a placeholder. You must replace it with the actual URL of your service.
SERVICE_URL = "http://localhost:5000/reconcile"
DATASET_DIR = "dataset"
PRODUCTION_DIR = os.path.join(DATASET_DIR, "production")
DEVELOPMENT_DIR = os.path.join(DATASET_DIR, "development")

def run_reconciliation_test(file_path: str, service_url: str):
    """
    Loads a JSON dataset, sends reconciliation queries, and prints the results.

    Args:
        file_path (str): The path to the JSON dataset file.
        service_url (str): The URL of the reconciliation service endpoint.
    """
    print(f"\n--- Testing dataset: {os.path.basename(file_path)} ---")
    
    # Load the test data from the JSON file.
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            test_data = json.load(f)
    except FileNotFoundError:
        print(f"ERROR: File not found at {file_path}")
        return
    except json.JSONDecodeError:
        print(f"ERROR: Invalid JSON in file at {file_path}")
        return

    # Prepare a list of queries for the API call.
    queries: Dict[str, Dict[str, str]] = {}
    for i, item in enumerate(test_data):
        # We use a unique key for each query (e.g., "q0", "q1", ...)
        queries[f"q{i}"] = {"query": item.get("query", "")}

    # Construct the payload for the POST request.
    payload = {"queries": json.dumps(queries)}

    # Send the request to the reconciliation service.
    try:
        response = requests.post(service_url, data=payload)
        response.raise_for_status()  # Raises an HTTPError for bad responses (4xx or 5xx)
        api_results: Dict[str, Any] = response.json()
    except requests.exceptions.RequestException as e:
        print(f"ERROR: Failed to connect to service at {service_url}. Please ensure the service is running.")
        print(f"Exception: {e}")
        return
    except json.JSONDecodeError:
        print("ERROR: Invalid JSON response from the API.")
        print("Response content:", response.text)
        return

    # Process and validate the results.
    for i, item in enumerate(test_data):
        query_key = f"q{i}"
        
        # Check if the API returned a result for this query.
        if query_key not in api_results:
            print(f"FAIL: '{item['query']}' - No result found for query key '{query_key}'")
            continue

        query_result = api_results[query_key].get("result", [])
        
        # Check if the result list is not empty.
        if not query_result:
            print(f"FAIL: '{item['query']}' - Result list is empty")
            continue

        # Simple validation: Check if the top candidate's name matches the expected name.
        top_candidate = query_result[0]
        reconciled_name = top_candidate.get("name", "")
        expected_name = item.get("name", "")

        # A successful match.
        if reconciled_name == expected_name:
            print(f"SUCCESS: '{item['query']}' -> '{reconciled_name}'")
        else:
            print(f"FAIL: '{item['query']}' - Expected '{expected_name}', got '{reconciled_name}'")

def main():
    """
    Main function to discover and run all test scripts.
    """
    print("Starting reconciliation service test suite...")
    print("------------------------------------------")

    # Get a list of all JSON files in the development and production directories.
    all_files = []
    if os.path.exists(DEVELOPMENT_DIR):
        for filename in os.listdir(DEVELOPMENT_DIR):
            if filename.endswith(".json"):
                all_files.append(os.path.join(DEVELOPMENT_DIR, filename))
    
    if os.path.exists(PRODUCTION_DIR):
        for filename in os.listdir(PRODUCTION_DIR):
            if filename.endswith(".json"):
                all_files.append(os.path.join(PRODUCTION_DIR, filename))
    
    if not all_files:
        print("No test dataset files found. Please run the generation scripts first.")
        return

    # Run the tests for each discovered file.
    for file in all_files:
        run_reconciliation_test(file, SERVICE_URL)

if __name__ == "__main__":
    main()


--- File: analysis\performance_analysis.py ---
Words: 157
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ttest_ind

# Sample data (replace with actual test results)
latencies = {
    'reconcile': [150, 200, 180, 220, 190, 210, 170, 230, 195, 205],
    'stream_chunk': [120, 130, 140, 110, 150, 125, 135, 145, 115, 130]
}
accuracies = {
    'reconcile': [0.95, 0.90, 0.92, 0.88, 0.94, 0.91, 0.89, 0.93, 0.90, 0.92],
    'stream_chunk': [0.85, 0.87, 0.90, 0.88, 0.86, 0.89, 0.87, 0.88, 0.86, 0.90]
}

# Statistical significance
reconcile_lat = latencies['reconcile']
stream_lat = latencies['stream_chunk']
t_stat_lat, p_value_lat = ttest_ind(reconcile_lat, stream_lat)
print(f"Latency T-test: t={t_stat_lat:.2f}, p={p_value_lat:.4f}")

reconcile_acc = accuracies['reconcile']
stream_acc = accuracies['stream_chunk']
t_stat_acc, p_value_acc = ttest_ind(reconcile_acc, stream_acc)
print(f"Accuracy T-test: t={t_stat_acc:.2f}, p={p_value_acc:.4f}")

# Visualizations
df_lat = pd.DataFrame({'Reconcile': reconcile_lat, 'Stream Chunk': stream_lat})
df_acc = pd.DataFrame({'Reconcile': accuracies['reconcile'], 'Stream Chunk': accuracies['stream_chunk']})

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
sns.boxplot(data=df_lat)
plt.title('Latency Distribution (ms)')
plt.ylabel('Latency (ms)')
plt.subplot(1, 2, 2)
sns.boxplot(data=df_acc)
plt.title('Accuracy Distribution')
plt.ylabel('Accuracy')
plt.savefig('performance.png')
plt.show()

# Summary statistics
print("
Latency Summary:")
print(df_lat.describe())
print("
Accuracy Summary:")
print(df_acc.describe())


--- File: scripts\dataset_generator.py ---
Words: 605
import json
import random
import os

def create_dataset_dir(env):
    """Ensures the dataset directory exists."""
    os.makedirs(f'../dataset/{env}', exist_ok=True)

def generate_mock_data(size=100):
    """Generates a large mock dataset for testing purposes."""
    dataset = []
    
    # Core entities
    core_entities = [
        {"name": "Apple Inc.", "query": "Apple"},
        {"name": "Microsoft Corp.", "query": "Microsoft"},
        {"name": "London", "query": "London"},
        {"name": "Albert Einstein", "query": "Einstein"},
        {"name": "The Godfather", "query": "Godfather"},
    ]

    # Expert Knowledge (Critical Fields)
    expert_entities = [
        {"name": "Myocardial Infarction", "query": "heart attack", "type": "medical_condition"},
        {"name": "Neural Network", "query": "backpropagation algorithm", "type": "AI"},
        {"name": "Quantum Entanglement", "query": "quantum entanglement", "type": "physics"},
        {"name": "Sarbanes-Oxley Act", "query": "SOX Act", "type": "legal"},
        {"name": "Gross Domestic Product", "query": "GDP", "type": "economics"},
    ]

    # Special Cases (Fine-Tuning)
    special_cases = [
        {"name": "The Flash (DC Comics)", "query": "Flash"},
        {"name": "Taylor Swift", "query": "Taylor Swift"},
        {"name": "Tyler Swift", "query": "Tyler Swift"},
        {"name": "The Lord of the Rings: The Fellowship of the Ring", "query": "Fellowship of the Ring"},
        {"name": "N.W.A.", "query": "NWA"}
    ]

    # Combine all data sources to create a rich dataset
    data_sources = [core_entities, expert_entities, special_cases]

    # Generate the requested number of data points
    for i in range(size):
        # Select a random entity type from our data sources
        source = random.choice(data_sources)
        item = random.choice(source).copy()

        # Introduce some variation (e.g., misspellings, new queries)
        if i % 5 == 0:
            item["query"] = f"A variant of {item['query']}"
        elif i % 7 == 0:
            item["query"] = item["query"].replace('e', 'ee').replace('a', 'aa')
        
        dataset.append(item)
    import json
import random
import os

def create_dataset_dir(env):
    """Ensures the dataset directory exists."""
    os.makedirs(f'../dataset/{env}', exist_ok=True)

def generate_mock_data(size=100):
    """Generates a large mock dataset for testing purposes."""
    dataset = []
    
    # Core entities
    core_entities = [
        {"name": "Apple Inc.", "query": "Apple"},
        {"name": "Microsoft Corp.", "query": "Microsoft"},
        {"name": "London", "query": "London"},
        {"name": "Albert Einstein", "query": "Einstein"},
        {"name": "The Godfather", "query": "Godfather"},
    ]

    # Expert Knowledge (Critical Fields)
    expert_entities = [
        {"name": "Myocardial Infarction", "query": "heart attack", "type": "medical_condition"},
        {"name": "Neural Network", "query": "backpropagation algorithm", "type": "AI"},
        {"name": "Quantum Entanglement", "query": "quantum entanglement", "type": "physics"},
        {"name": "Sarbanes-Oxley Act", "query": "SOX Act", "type": "legal"},
        {"name": "Gross Domestic Product", "query": "GDP", "type": "economics"},
    ]

    # Special Cases (Fine-Tuning)
    special_cases = [
        {"name": "The Flash (DC Comics)", "query": "Flash"},
        {"name": "Taylor Swift", "query": "Taylor Swift"},
        {"name": "Tyler Swift", "query": "Tyler Swift"},
        {"name": "The Lord of the Rings: The Fellowship of the Ring", "query": "Fellowship of the Ring"},
        {"name": "N.W.A.", "query": "NWA"}
    ]

    # Combine all data sources to create a rich dataset
    data_sources = [core_entities, expert_entities, special_cases]

    # Generate the requested number of data points
    for i in range(size):
        # Select a random entity type from our data sources
        source = random.choice(data_sources)
        item = random.choice(source).copy()

        # Introduce some variation (e.g., misspellings, new queries)
        if i % 5 == 0:
            item["query"] = f"A variant of {item['query']}"
        elif i % 7 == 0:
            item["query"] = item["query"].replace('e', 'ee').replace('a', 'aa')
        
        dataset.append(item)
    
    return dataset

def save_dataset(dataset, filename, env):
    """Saves the dataset to a JSON file in the specified environment directory."""
    create_dataset_dir(env)
    file_path = f'../dataset/{env}/{filename}.json'
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, indent=2)
    print(f"Saved {len(dataset)} items to {file_path}")

if __name__ == "__main__":
    # Generate a rich and diverse special dataset with 100 entries
    special_data = generate_mock_data(size=100)
    save_dataset(special_data, 'special-100-entries', 'special')

    # Example for other environments (e.g., development)
    # dev_data = generate_mock_data(size=100)
    # save_dataset(dev_data, 'dev-100-entries', 'development')
    

    return dataset

def save_dataset(dataset, filename, env):
    """Saves the dataset to a JSON file in the specified environment directory."""
    create_dataset_dir(env)
    file_path = f'../dataset/{env}/{filename}.json'
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, indent=2)
    print(f"Saved {len(dataset)} items to {file_path}")

if __name__ == "__main__":
    # Generate a rich and diverse special dataset with 100 entries
    special_data = generate_mock_data(size=100)
    save_dataset(special_data, 'special-100-entries', 'special')

    # Example for other environments (e.g., development)
    # dev_data = generate_mock_data(size=100)
    # save_dataset(dev_data, 'dev-100-entries', 'development')
    


--- File: test_reconciliation.js ---
Words: 521
import { promises as fs } from 'fs';
import path from 'path';

// --- Configuration ---
// Set the base URL for your reconciliation service here.
// NOTE: This is a placeholder. You must replace it with the actual URL of your service.
const SERVICE_URL = "http://localhost:5000/reconcile";
const DATASET_DIR = "dataset";
const PRODUCTION_DIR = path.join(DATASET_DIR, "production");
const DEVELOPMENT_DIR = path.join(DATASET_DIR, "development");

/**
 * Loads a JSON dataset, sends reconciliation queries, and prints the results.
 *
 * @param {string} filePath The path to the JSON dataset file.
 * @param {string} serviceUrl The URL of the reconciliation service endpoint.
 */
async function runReconciliationTest(filePath, serviceUrl) {
    console.log(\n--- Testing dataset: \ ---);

    let testData;
    // Load the test data from the JSON file.
    try {
        const fileContent = await fs.readFile(filePath, 'utf-8');
        testData = JSON.parse(fileContent);
    } catch (error) {
        if (error.code === 'ENOENT') {
            console.error(ERROR: File not found at \);
        } else {
            console.error(ERROR: Invalid JSON in file at \);
            console.error(error.message);
        }
        return;
    }

    // Prepare a list of queries for the API call.
    const queries = {};
    testData.forEach((item, i) => {
        // We use a unique key for each query (e.g., "q0", "q1", ...)
        queries[q\] = { "query": item.query || "" };
    });

    // Send the request to the reconciliation service.
    try {
        const response = await fetch(serviceUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ queries: JSON.stringify(queries) })
        });

        if (!response.ok) {
            throw new Error(HTTP error! Status: \);
        }

        const apiResults = await response.json();

        // Process and validate the results.
        testData.forEach((item, i) => {
            const queryKey = q\;
            
            // Check if the API returned a result for this query.
            if (!apiResults[queryKey]) {
                console.log(FAIL: '\' - No result found for query key '\');
                return;
            }

            const queryResult = apiResults[queryKey].result || [];
            
            // Check if the result list is not empty.
            if (queryResult.length === 0) {
                console.log(FAIL: '\' - Result list is empty);
                return;
            }

            // Simple validation: Check if the top candidate's name matches the expected name.
            const topCandidate = queryResult[0];
            const reconciledName = topCandidate.name || "";
            const expectedName = item.name || "";

            // A successful match.
            if (reconciledName === expectedName) {
                console.log(SUCCESS: '\' -> '\');
            } else {
                console.log(FAIL: '\' - Expected '\', got '\');
            }
        });

    } catch (error) {
        console.error(ERROR: Failed to connect to service at \. Please ensure the service is running.);
        console.error(Exception: \);
    }
}

async function main() {
    console.log("Starting reconciliation service test suite...");
    console.log("------------------------------------------");

    const allFiles = [];

    // Get a list of all JSON files in the development and production directories.
    try {
        if (await fs.stat(DEVELOPMENT_DIR).then(() => true).catch(() => false)) {
            const devFiles = (await fs.readdir(DEVELOPMENT_DIR)).filter(filename => filename.endsWith(".json"));
            allFiles.push(...devFiles.map(file => path.join(DEVELOPMENT_DIR, file)));
        }
    } catch (e) { /* directory does not exist */ }

    try {
        if (await fs.stat(PRODUCTION_DIR).then(() => true).catch(() => false)) {
            const prodFiles = (await fs.readdir(PRODUCTION_DIR)).filter(filename => filename.endsWith(".json"));
            allFiles.push(...prodFiles.map(file => path.join(PRODUCTION_DIR, file)));
        }
    } catch (e) { /* directory does not exist */ }

    if (allFiles.length === 0) {
        console.log("No test dataset files found. Please run the generation scripts first.");
        return;
    }

    // Run the tests for each discovered file.
    for (const file of allFiles) {
        await runReconciliationTest(file, SERVICE_URL);
    }
}

main();


--- File: netlify\functions\api.js ---
Words: 231
const express = require('express');
const cors = require('cors');
const bodyParser = require('body-parser');
const path = require('path');

const app = express();

// Middleware
app.use(cors());
app.use(bodyParser.json());
app.use(bodyParser.urlencoded({ extended: true }));


const baseUrl = process.env.BASE_URL || 'http://localhost:8888';

  definition: {
    openapi: '3.0.3',
    info: {
      title: 'Universal Reconciliation Service API',
      version: '1.0.0',
      description: 'API for reconciliation service using Express and Gemini API',
      contact: { name: 'Google', email: 'support@example.com' },
      license: { name: 'MIT', url: 'https://opensource.org/licenses/MIT' },
    },
    servers: [{ url: baseUrl, description: 'API base URL' }],
  },
  apis: [path.join(__dirname, 'routes', '*.js')],
};


  res.setHeader('Content-Type', 'application/json');
});

// Import your route handlers
const reconcileRouter = require('./routes/reconcile');
const metadataRouter = require('./routes/metadata');
const previewRouter = require('./routes/preview');
const suggestRouter = require('./routes/suggest-entity');
const suggestPropertyRouter = require('./routes/suggest-property');
const suggestTypeRouter = require('./routes/suggest-type');
const extendRouter = require('./routes/extend');
const extendProposeRouter = require('./routes/extend-propose');
const streamChunkRouter = require('./routes/stream-chunk');

// Register routes
app.use('/', metadataRouter);
app.use('/reconcile', reconcileRouter);
app.use('/preview', previewRouter);
app.use('/suggest/entity', suggestRouter);
app.use('/suggest/property', suggestPropertyRouter);
app.use('/suggest/type', suggestTypeRouter);
app.use('/extend', extendRouter);
app.use('/extend/propose', extendProposeRouter);
app.use('/stream-chunk', streamChunkRouter);

// Catch-all 404 for unknown routes
app.use((req, res, next) => {
  res.status(404).json({
    error: 'Not Found',
    message: `The requested URL ${req.originalUrl} was not found on this server.`,
  });
});

// Global error handler (production ready)
app.use((err, req, res, next) => {
  console.error('Server error:', err.stack || err);

  // Customize error response based on environment
  const response = {
    error: 'Internal Server Error',
  };

  if (process.env.NODE_ENV !== 'production') {
    response.message = err.message;
    response.stack = err.stack;
  }

  res.status(500).json(response);
});

module.exports = app;


--- File: netlify\functions\extend-propose.js ---
Words: 120
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { type = '', limit = 10 } = JSON.parse(event.body || '{}');
    const prompt = Propose properties for type "", limit to . Return as JSON with properties array of {id, name}.;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        properties: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Propose properties error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ properties: [] }),
    };
  }
};


--- File: netlify\functions\extend.js ---
Words: 147
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { ids = [], properties = [] } = JSON.parse(event.body || '{}');
    const results = { rows: {} };

    for (const id of ids) {
      const prompt = Extend data for entity ID "" with properties: . Return as JSON with values for each property as array of {str or num}.;
      const llmResponse = await callGemini(prompt, {
        type: "object",
        properties: properties.reduce((acc, prop) => ({
          ...acc,
          [prop.id]: {
            type: "array",
            items: { type: "object", properties: { str: { type: "string" }, num: { type: "number" } } },
          },
        }), {}),
      });
      results.rows[id] = llmResponse;
    }

    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(results),
    };
  } catch (error) {
    console.error('Extend error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ rows: {} }),
    };
  }
};


--- File: netlify\functions\metadata.js ---
Words: 117
exports.handler = async (event, context) => {
  // Use environment variable BASE_URL or fallback to localhost
  const baseUrl = process.env.BASE_URL || "http://localhost:8888";

  return {
    statusCode: 200,
    headers: { "Access-Control-Allow-Origin": "*" },
    body: JSON.stringify({
      name: "Universal Reconciliation Service",
      identifierSpace: "http://example.com/identifiers",
      schemaSpace: "http://example.com/schemas",
      defaultTypes: [{ id: "/general", name: "General Entity" }],
      view: { url: "http://example.com/view/{{id}}" },
      preview: { url: `${baseUrl}/preview?id={{id}}`, width: 400, height: 200 },
      suggest: {
        entity: { service_url: baseUrl, service_path: "/suggest/entity" },
        type: { service_url: baseUrl, service_path: "/suggest/type" },
        property: { service_url: baseUrl, service_path: "/suggest/property" },
      },
      extend: {
        propose_properties: { service_url: baseUrl, service_path: "/extend/propose" },
        property_settings: [
          { name: "maxItems", label: "Maximum number of values", type: "number", default: 1 },
        ],
      },
    }),
  };
};


--- File: netlify\functions\preview.js ---
Words: 98
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { id = '' } = event.queryStringParameters;
    const prompt = Generate a preview for entity with ID "". Return as JSON with html containing the preview content.;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: { html: { type: "string" } },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Preview error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ html: '<p>Error generating preview</p>' }),
    };
  }
};


--- File: netlify\functions\reconcile.js ---
Words: 113
const { callGemini, getReconcileSchema } = require('./utils');

exports.handler = async (event) => {
  try {
    const queries = JSON.parse(event.body?.queries || event.queryStringParameters?.queries || '{}');
    const callback = event.queryStringParameters?.callback;
    const results = {};

    for (const [key, query] of Object.entries(queries)) {
      const prompt = Reconcile query: , Type: , Limit: , Properties: ;
      const llmResponse = await callGemini(prompt, getReconcileSchema());
      results[key] = { result: llmResponse.result || [] };
    }

    const response = {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(results),
    };

    if (callback) {
      response.headers["Content-Type"] = "application/javascript";
      response.body = ${callback}();
    }

    return response;
  } catch (error) {
    console.error('Reconcile error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({}),
    };
  }
};


--- File: netlify\functions\stream-chunk.js ---
Words: 212
const fs = require('fs').promises;
const path = require('path');
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { input } = JSON.parse(event.body || '{}');
    if (!input) {
      return {
        statusCode: 400,
        headers: { "Access-Control-Allow-Origin": "*" },
        body: JSON.stringify({ error: 'Input required' }),
      };
    }

    const chunks = [];
    for (let i = 0; i < input.length; i += 3) {
      chunks.push(input.slice(i, i + 3));
    }

    const dataDir = path.join(__dirname, '../../data');
    const files = await fs.readdir(dataDir);
    const matches = [];

    for (const file of files) {
      if (file.endsWith('.txt') || file.endsWith('.json')) {
        const content = await fs.readFile(path.join(dataDir, file), 'utf8');
        let fileData = content;
        if (file.endsWith('.json')) {
          fileData = JSON.stringify(JSON.parse(content));
        }

        for (const chunk of chunks) {
          if (fileData.toLowerCase().includes(chunk.toLowerCase())) {
            const prompt = Match chunk "" in file . Return context (20 chars before/after).;
            const llmResponse = await callGemini(prompt, {
              type: 'object',
              properties: { context: { type: 'string' } },
            });
            matches.push({
              chunk,
              file,
              context: llmResponse.context || fileData.slice(Math.max(0, fileData.indexOf(chunk) - 20), fileData.indexOf(chunk) + 23),
            });
          }
        }
      }
    }

    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ matches }),
    };
  } catch (error) {
    console.error('Stream chunk error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ matches: [] }),
    };
  }
};


--- File: netlify\functions\suggest-entity.js ---
Words: 124
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { prefix = '', type = '' } = event.queryStringParameters;
    const prompt = Suggest entities starting with "" for type "". Return as JSON with result array of {id, name, description}.;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        result: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
              description: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Suggest entity error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ result: [] }),
    };
  }
};


--- File: netlify\functions\suggest-property.js ---
Words: 118
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { prefix = '', type = '' } = event.queryStringParameters;
    const prompt = Suggest properties starting with "" for type "". Return as JSON with result array of {id, name}.;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        result: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Suggest property error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ result: [] }),
    };
  }
};


--- File: netlify\functions\suggest-type.js ---
Words: 112
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { prefix = '' } = event.queryStringParameters;
    const prompt = Suggest types starting with "". Return as JSON with result array of {id, name}.;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        result: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Suggest type error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ result: [] }),
    };
  }
};


--- File: netlify\functions\utils.js ---
Words: 139
const fetch = require('node-fetch');

async function callGemini(prompt, schema) {
  const apiKey = process.env.GEMINI_API_KEY;
  const response = await fetch(https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      contents: [{ role: 'user', parts: [{ text: prompt }] }],
      generationConfig: { responseMimeType: 'application/json', responseSchema: schema },
    }),
  });

  if (!response.ok) {
    throw new Error(API error: );
  }

  const result = await response.json();
  return JSON.parse(result.candidates[0].content.parts[0].text);
}

function getReconcileSchema() {
  return {
    type: 'object',
    properties: {
      result: {
        type: 'array',
        items: {
          type: 'object',
          properties: {
            id: { type: 'string' },
            name: { type: 'string' },
            score: { type: 'number' },
            match: { type: 'boolean' },
            type: {
              type: 'array',
              items: { type: 'object', properties: { id: { type: 'string' }, name: { type: 'string' } } },
            },
          },
        },
      },
    },
  };
}

module.exports = { callGemini, getReconcileSchema };


--- File: src\api.js ---
Words: 103
const express = require('express');
const metadataRouter = require('./routes/metadata');
const reconcileRouter = require('./routes/reconcile');
const suggestEntityRouter = require('./routes/suggest-entity');
// ...other routers
const previewRouter = require('./routes/preview');
const extendProposeRouter = require('./routes/extend-propose');
const extendRouter = require('./routes/extend');
const streamChunkRouter = require('./routes/stream-chunk');

const app = express();
app.use(express.json());

// Enable CORS
app.use((req, res, next) => {
  res.set('Access-Control-Allow-Origin', '*');
  next();
});

// Mount routes
app.use('/metadata', metadataRouter);
app.use('/reconcile', reconcileRouter);
app.use('/suggest/entity', suggestEntityRouter);
app.use('/suggest/type', require('./routes/suggest-type'));
app.use('/suggest/property', require('./routes/suggest-property'));
app.use('/preview', previewRouter);
app.use('/extend/propose', extendProposeRouter);
app.use('/extend', extendRouter);
app.use('/stream-chunk', streamChunkRouter);

// Error middleware
app.use((err, req, res, next) => {
  console.error(err);
  res.status(err.status || 500).json({
    status: err.status || 500,
    error: err.name,
    message: err.message,
    timestamp: new Date().toISOString(),
  });
});

module.exports = app;


--- File: src\swagger.js ---
Words: 88
const swaggerJsdoc = require('swagger-jsdoc');
const swaggerUi = require('swagger-ui-express');

const baseUrl = process.env.BASE_URL || 'http://localhost:8888';

const options = {
  definition: {
    openapi: '3.0.3',
    info: {
      title: 'Universal Reconciliation Service API',
      version: '1.0.0',
      description: 'API for reconciliation service using Express and Gemini API',
      contact: {
        name: 'Google',
        email: 'support@example.com',
      },
      license: {
        name: 'MIT',
        url: 'https://opensource.org/licenses/MIT',
      },
    },
    servers: [
      {
        url: baseUrl,
        description: 'Base URL of the API',
      },
    ],
  },
  apis: ['./netlify/functions/routes/*.js'],
};

const swaggerSpec = swaggerJsdoc(options);

function setupSwagger(app) {
  app.use('/api-docs', swaggerUi.serve, swaggerUi.setup(swaggerSpec));
}

module.exports = setupSwagger;


--- File: src\utils.js ---
Words: 612
const { GoogleGenerativeAI } = require('@google/generative-ai');
const { v4: uuidv4 } = require('uuid');
const path = require('path');
const fs = require('fs');
require('dotenv').config();

const API_KEY = proceupdatess.env.GEMINI_API_KEY;
if (!API_KEY) {
  console.error("GEMINI_API_KEY is not set. Please set the environment variable.");
  process.exit(1);
}
const genAI = new GoogleGenerativeAI(API_KEY);

// Helper function to get the Gemini model response
async function getModelResponse(prompt, isJson, useSearch) {
  try {
    const generationConfig = isJson ? { responseMimeType: "application/json" } : {};
    const tools = useSearch ? [{ google_search: {} }] : undefined;

    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash-preview-05-20", generationConfig, tools });

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    return { text };
  } catch (error) {
    console.error('Gemini API error:', error);
    throw new Error('Failed to get response from Gemini API.');
  }
}

// Helper function to get service metadata
function getServiceMetadata() {
  return {
    name: "Universal Reconciliation Service API",
    identifierSpace: "[http://www.freebase.com/ns/freebase](http://www.freebase.com/ns/freebase)",
    schemaSpace: "[http://www.freebase.com/ns/type.type](http://www.freebase.com/ns/type.type)",
    view: {
      url: "{{id}}"
    },
    defaultTypes: [{
      id: "/common/topic",
      name: "Topic"
    }],
    reconcile: {
      path: "/reconcile",
      serviceUrl: "/.netlify/functions/api"
    },
    suggest: {
      entity: {
        path: "/suggest/entity",
        serviceUrl: "/.netlify/functions/api"
      },
      type: {
        path: "/suggest/type",
        serviceUrl: "/.netlify/functions/api"
      },
      property: {
        path: "/suggest/property",
        serviceUrl: "/.netlify/functions/api"
      }
    },
    preview: {
      path: "/preview",
      serviceUrl: "/.netlify/functions/api"
    },
    extend: {
      propose_properties: {
        path: "/extend/propose",
        serviceUrl: "/.netlify/functions/api"
      },
      serviceUrl: "/.netlify/functions/api"
    }
  };
}

// Helper function to handle reconciliation matching
async function getMatchingResults(queries) {
  const results = {};
  for (const qid in queries) {
    const query = queries[qid];
    const userPrompt = `Reconcile the entity "${query.query}" against entities of type "${query.type}". Provide a list of 5 possible matches in JSON format, each with a 'name', 'id', 'score' (0-100), and 'type' property. The 'score' should reflect the confidence of the match.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const matches = JSON.parse(modelResponse.text);

    results[qid] = {
      result: matches.map(match => ({
        id: match.id || uuidv4(),
        name: match.name,
        score: match.score / 100,
        match: match.score > 70 ? true : false,
        type: [{
          id: match.type,
          name: match.type
        }]
      }))
    };
  }
  return results;
}

// Helper function to handle suggestions
async function getSuggestions(type, prefix) {
  let userPrompt;
  switch (type) {
    case 'entity':
      userPrompt = `Suggest 5 entities related to "${prefix}" in JSON format. Each entity should have a 'name' and 'id'.`;
      break;
    case 'type':
      userPrompt = `Suggest 5 data types related to "${prefix}" in JSON format. Each type should have a 'name' and 'id'.`;
      break;
    case 'property':
      userPrompt = `Suggest 5 properties that start with "${prefix}" in JSON format. Each property should have a 'name' and 'id'.`;
      break;
    default:
      throw new Error(`Invalid suggestion type: ${type}`);
  }

  const modelResponse = await getModelResponse(userPrompt, true, false);
  const suggestions = JSON.parse(modelResponse.text);

  return {
    result: suggestions.map(s => ({
      id: s.id || uuidv4(),
      name: s.name,
      description: s.description || ""
    }))
  };
}

// Helper function to get preview HTML
async function getPreviewHTML(id) {
  const userPrompt = `Generate a short HTML description for an entity with the ID "${id}". Make sure the HTML is well-formed.`;
  const modelResponse = await getModelResponse(userPrompt, true, false);
  return modelResponse.text;
}

// Helper function to get extended properties
async function getExtendedProperties(ids, properties) {
  const data = {};
  for (const id of ids) {
    const userPrompt = `For the entity with ID "${id}", retrieve the values for the following properties: ${properties.map(p => p.id).join(', ')}. Provide the result in a JSON object where keys are the property IDs and values are the corresponding values.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const values = JSON.parse(modelResponse.text);
    data[id] = values;
  }
  return {
    meta: properties.map(p => ({ id: p.id, name: p.name })),
    rows: ids.map(id => ({ id: id, values: properties.map(p => data[id][p.id] ? [{ str: data[id][p.id] }] : []) }))
  };
}


module.exports = {
  getServiceMetadata,
  getModelResponse,
  getMatchingResults,
  getSuggestions,
  getPreviewHTML,
  getExtendedProperties,
};



--- File: src\routes\extend-propose.js ---
Words: 149
/**
 * @swagger
 * /extend-propose:
 *   get:
 *     summary: Example GET endpoint for extend-propose
 *     description: Detailed description for the extend-propose endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const { v4: uuidv4 } = require('uuid');

// Extend Propose Route
// This endpoint proposes properties for data extension.
router.post('/', async (req, res) => {
  try {
    const type = req.body.type;
    const userPrompt = `Propose 5 properties to extend data for the entity type "${type}". Provide the suggestions in JSON format. Each property should have an 'id' and 'name'.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const properties = JSON.parse(modelResponse.text);

    res.status(200).json({
      properties: properties.map(p => ({
        id: p.id || uuidv4(),
        name: p.name
      }))
    });
  } catch (error) {
    console.error('Extend propose error:', error);
    res.status(500).json({ error: 'Failed to propose properties.' });
  }
});

module.exports = router;


--- File: src\routes\extend.js ---
Words: 207
/**
 * @swagger
 * /extend:
 *   get:
 *     summary: Example GET endpoint for extend
 *     description: Detailed description for the extend endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');

// Extend Route
// This endpoint extends data by adding properties to entities.
router.post('/', async (req, res) => {
  try {
    const ids = req.body.ids;
    const properties = req.body.properties;

    if (!ids || !properties || !Array.isArray(ids) || !Array.isArray(properties)) {
      return res.status(400).json({ error: 'Missing or invalid ids or properties.' });
    }

    const data = {};
    for (const id of ids) {
      const userPrompt = `For the entity with ID "${id}", retrieve the values for the following properties: ${properties.map(p => p.id).join(', ')}. Provide the result in a JSON object where keys are the property IDs and values are the corresponding values.`;
      const modelResponse = await getModelResponse(userPrompt, true, false);

      const values = JSON.parse(modelResponse.text);
      data[id] = values;
    }

    res.status(200).json({
      meta: properties.map(p => ({ id: p.id, name: p.name })),
      rows: ids.map(id => ({ id: id, values: properties.map(p => data[id][p.id] ? [{ str: data[id][p.id] }] : []) }))
    });
  } catch (error) {
    console.error('Extend error:', error);
    res.status(500).json({ error: 'Failed to extend data.' });
  }
});

module.exports = router;


--- File: src\routes\metadata.js ---
Words: 137
/**
 * @swagger
 * /metadata:
 *   get:
 *     summary: Example GET endpoint for metadata
 *     description: Detailed description for the metadata endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
// src/routes/metadata.js
const express = require('express');
const router = express.Router();

router.get('/', (req, res) => {
  const baseUrl = `${req.protocol}://${req.get('host')}`;
  res.json({
    name: 'Universal Reconciliation Service',
    identifierSpace: 'http://example.com/identifiers',
    schemaSpace: 'http://example.com/schemas',
    defaultTypes: [{ id: '/general', name: 'General Entity' }],
    view: { url: 'http://example.com/view/{{id}}' },
    preview: {
      url: `${baseUrl}/preview?id={{id}}`,
      width: 400,
      height: 200,
    },
    suggest: {
      entity: { service_url: baseUrl, service_path: '/suggest/entity' },
      type: { service_url: baseUrl, service_path: '/suggest/type' },
      property: { service_url: baseUrl, service_path: '/suggest/property' },
    },
    extend: {
      propose_properties: { service_url: baseUrl, service_path: '/extend/propose' },
      property_settings: [
        {
          name: 'maxItems',
          label: 'Maximum number of values',
          type: 'number',
          default: 1,
        },
      ],
    },
  });
});

module.exports = router;


--- File: src\routes\preview.js ---
Words: 128
/**
 * @swagger
 * /preview:
 *   get:
 *     summary: Example GET endpoint for preview
 *     description: Detailed description for the preview endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');

// Preview Route
// This endpoint generates a preview of an entity.
router.get('/', async (req, res) => {
  try {
    const id = req.query.id;
    if (!id) {
      return res.status(400).send('Entity ID is required.');
    }

    const userPrompt = `Generate a short HTML description for an entity with the ID "${id}". Make sure the HTML is well-formed.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const htmlContent = modelResponse.text;

    res.status(200).send(htmlContent);
  } catch (error) {
    console.error('Preview error:', error);
    res.status(500).send('Failed to generate preview.');
  }
});

module.exports = router;


--- File: src\routes\stream-chunk.js ---
Words: 203
/**
 * @swagger
 * /stream-chunk:
 *   get:
 *     summary: Example GET endpoint for stream-chunk
 *     description: Detailed description for the stream-chunk endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const path = require('path');
const fs = require('fs');

// Stream Chunk Route
// This endpoint handles real-time stream chunk matching.
router.post('/', async (req, res) => {
  try {
    const { input, fileName } = req.body;
    if (!input || !fileName) {
      return res.status(400).json({ error: 'Input text and file name are required.' });
    }

    const filePath = path.join(__dirname, '..', '..', 'data', fileName);
    if (!fs.existsSync(filePath)) {
      return res.status(404).json({ error: 'File not found.' });
    }

    const fileContent = fs.readFileSync(filePath, 'utf-8');
    const userPrompt = `Given the input chunk "${input}" and the following data:\n\n---\n${fileContent}\n---\n\nDetermine the best match from the data for the input chunk. Provide a JSON object with 'match' and 'confidence' (0-100) properties. If no match is found, set 'match' to null.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const result = JSON.parse(modelResponse.text);

    res.status(200).json({
      match: result.match,
      confidence: result.confidence / 100
    });
  } catch (error) {
    console.error('Stream chunk error:', error);
    res.status(500).json({ error: 'Failed to process stream chunk.' });
  }
});

module.exports = router;



--- File: src\routes\suggest-property.js ---
Words: 195
/**
 * @swagger
 * /suggest-property:
 *   get:
 *     summary: Example GET endpoint for suggest-property
 *     description: Detailed description for the suggest-property endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const { v4: uuidv4 } = require('uuid');

// Suggest Property Route
// This endpoint suggests properties based on a query.
router.get('/', async (req, res) => {
  try {
    const query = req.query.prefix;
    const type = req.query.type;
    if (!query) {
      return res.status(400).json({ error: 'Query prefix is required.' });
    }

    let userPrompt;
    if (type) {
      userPrompt = `Suggest 5 properties for a data type named "${type}" that start with "${query}". Provide the suggestions in JSON format, each with a 'name' and 'id'.`;
    } else {
      userPrompt = `Suggest 5 properties that start with "${query}" in JSON format. Each property should have a 'name' and 'id'.`;
    }
    
    const modelResponse = await getModelResponse(userPrompt, true, false);
    const suggestions = JSON.parse(modelResponse.text);

    res.status(200).json({
      result: suggestions.map(s => ({
        id: s.id || uuidv4(),
        name: s.name
      }))
    });
  } catch (error) {
    console.error('Suggest property error:', error);
    res.status(500).json({ error: 'Failed to get property suggestions.' });
  }
});

module.exports = router;


--- File: tests\accuracy.test.js ---
Words: 132
const request = require('supertest');

// Set the base URL from an environment variable for flexibility.
const baseUrl = process.env.BASE_URL || 'http://localhost:8888/.netlify/functions/api';

describe('Accuracy Tests', () => {
  // Tests the accuracy of the reconciliation endpoint.
  test('Reconcile accuracy for a known entity', async () => {
    const response = await request(baseUrl)
      .post('/reconcile')
      .send({ queries: { q0: { query: 'Paris', type: '/location' } } });

    // The first result should contain "Paris" and have a high confidence score.
    const result = response.body.q0.result[0];
    expect(result.name).toContain('Paris');
    expect(result.score).toBeGreaterThan(0.8);
  });

  // Tests the accuracy of the stream-chunk endpoint.
  test('Stream chunk accuracy for a valid input', async () => {
    const response = await request(baseUrl)
      .post('/stream-chunk')
      .send({ input: 'Apple Inc.', fileName: 'sample.json' });

    // The API should return a high-confidence match.
    const result = response.body;
    expect(result.match).toBe('Apple Inc.');
    expect(result.confidence).toBeGreaterThan(0.8);
  });
});


--- File: tests\performance.test.js ---
Words: 138
const request = require('supertest');

// Set the base URL from an environment variable for flexibility.
const baseUrl = process.env.BASE_URL || 'http://localhost:8888/.netlify/functions/api';

describe('Performance Tests', () => {
  // Tests the latency of the reconciliation endpoint.
  test('Reconcile endpoint latency', async () => {
    const start = Date.now();
    await request(baseUrl)
      .post('/reconcile')
      .send({ queries: { q0: { query: 'Paris', type: '/location', limit: 3 } } });
      
    const latency = Date.now() - start;
    console.log(`Reconcile latency: ${latency}ms`);
    // Ensure the response time is less than 10 seconds.
    expect(latency).toBeLessThan(10000);
  });

  // Tests the latency of the stream chunk endpoint.
  test('Stream chunk endpoint latency', async () => {
    const start = Date.now();
    await request(baseUrl)
      .post('/stream-chunk')
      .send({ input: 'Apple Inc.', fileName: 'sample.json' });

    const latency = Date.now() - start;
    console.log(`Stream chunk latency: ${latency}ms`);
    // Ensure the response time is less than 10 seconds.
    expect(latency).toBeLessThan(10000);
  });
});


--- File: tests\stream.test.js ---
Words: 137
const request = require('supertest');

// Set the base URL from an environment variable for flexibility.
const baseUrl = process.env.BASE_URL || 'http://localhost:8888/.netlify/functions/api';

describe('Stream Chunk Tests', () => {
  // Tests that the endpoint returns the correct structure for a valid chunk.
  test('Returns correct match and confidence for a valid chunk', async () => {
    const response = await request(baseUrl)
      .post('/stream-chunk')
      .send({ input: 'Apple Inc.', fileName: 'sample.json' });
    
    // The new API returns a single `match` and `confidence` score.
    expect(response.status).toBe(200);
    expect(response.body).toHaveProperty('match');
    expect(response.body).toHaveProperty('confidence');
    expect(typeof response.body.match).toBe('string');
    expect(typeof response.body.confidence).toBe('number');
  });

  // Tests that the endpoint handles empty input gracefully.
  test('Handles empty input and missing filename', async () => {
    const response = await request(baseUrl)
      .post('/stream-chunk')
      .send({ input: '', fileName: '' });
      
    // The API should return a 400 Bad Request error.
    expect(response.status).toBe(400);
    expect(response.body.error).toBe('Input text and file name are required.');
  });
});


--- File: public\index.html ---
Words: 24
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Reconciliation Service</title>
</head>
<body>
  <h1>Reconciliation Service API</h1>
  <p>This site hosts backend functions only.</p>
</body>
</html>


--- File: project_analysis_script.ps1 ---
Words: 676
# Get the current directory name to use as the project name
$projectName = Get-Item -Path . | Select-Object -ExpandProperty Name

# Define the output file path based on the project name
$outputFile = ".\$($projectName)_ProjectSummary.txt"

# Get the full path of the current directory to use as a root for relative paths
$currentDirectory = Get-Location

# Define common source code file extensions
$sourceExtensions = @("*.cs", "*.py", "*.js", "*.java", "*.html", "*.css", "*.cpp", "*.h", "*.ts", "*.jsx", "*.tsx", "*.php", "*.rb", "*.go", "*.sh", "*.ps1", "*.bat")

# Define common dataset/data-related file extensions
$dataExtensions = @("*.json", "*.xml", "*.csv", "*.txt", "*.md", "*.yml", "*.yaml", "*.sql")

# Define files and directories to ignore
$excludePatterns = @("node_modules", ".env", ".git", ".gitignore", "package-lock.json", "yarn.lock", "*.log", "dist", "build", "bin", "obj", "*.lock", "*.zip", "*.rar", "*.exe", "*.dll")

# Initialize variables to track word counts
$totalSourceCodeWords = 0
$totalDataWords = 0

# --- Function to get a timestamp ---
function Get-Timestamp {
    return Get-Date -Format "yyyy-MM-dd HH:mm:ss"
}

# --- Function to write professional metadata ---
function Write-Metadata {
    param (
        [string]$filePath,
        [string]$projectName,
        [int]$sourceWords,
        [int]$dataWords
    )
    Add-Content -Path $filePath -Value "===== Project Summary ====="
    Add-Content -Path $filePath -Value "Project Name: $projectName"
    Add-Content -Path $filePath -Value "Generation Date: $(Get-Timestamp)"
    Add-Content -Path $filePath -Value "Generated By: PowerShell Script"
    Add-Content -Path $filePath -Value "Total Source Code Words: $sourceWords"
    Add-Content -Path $filePath -Value "Total Dataset/Text Words: $dataWords"
    Add-Content -Path $filePath -Value "Description: A comprehensive summary of the project's structure, source code, and data files, designed for secure LLM context submission."
    Add-Content -Path $filePath -Value "==========================="
    Add-Content -Path $filePath -Value "`n"
}

# Clear the output file if it already exists
if (Test-Path $outputFile) {
    Remove-Item $outputFile -Force
}

# Write a temporary metadata header to be updated later
Add-Content -Path $outputFile -Value "===== Project Summary =====
Project Name: universal-reconciliation-service
Generation Date: 2025-09-05 01:24:19
Generated By: PowerShell Script
Total Source Code Words: 6194
Total Dataset/Text Words: 16376
Description: A comprehensive summary of the project's structure, source code, and data files, designed for secure LLM context submission.
===========================
"

# Write the directory structure to the output file, excluding specified patterns
Add-Content -Path $outputFile -Value "===== Directory Structure ====="
$allFiles = Get-ChildItem -Recurse -File | Where-Object {
    $path = $_.FullName
    $shouldInclude = $true
    foreach ($pattern in $excludePatterns) {
        if ($path -like "*$pattern*") {
            $shouldInclude = $false
            break
        }
    }
    $shouldInclude
}

$directoryStructure = $allFiles | ForEach-Object { 
    $_.FullName.Replace($currentDirectory.Path + "\", "") 
} | Out-String
Add-Content -Path $outputFile -Value $directoryStructure

# Add a separator for source code files
Add-Content -Path $outputFile -Value "`n===== Source Code Files ====="

# Loop through source code files
foreach ($ext in $sourceExtensions) {
    $allFiles | Where-Object { $_.Name -like $ext } | ForEach-Object {
        $filePath = $_.FullName
        $relativePath = $filePath.Replace($currentDirectory.Path + "\", "")
        $fileContent = Get-Content -Path $filePath -Raw
        
        # Count words and add to total
        $wordCount = ($fileContent -split '\s+').Count
        $totalSourceCodeWords += $wordCount
        
        Add-Content -Path $outputFile -Value "`n--- File: $relativePath ---"
        Add-Content -Path $outputFile -Value "Words: $wordCount"
        Add-Content -Path $outputFile -Value $fileContent
    }
}

# Add a separator for dataset files
Add-Content -Path $outputFile -Value "`n===== Datasets and Text Files ====="

# Loop through dataset files
foreach ($ext in $dataExtensions) {
    $allFiles | Where-Object { $_.Name -like $ext } | ForEach-Object {
        $filePath = $_.FullName
        $relativePath = $filePath.Replace($currentDirectory.Path + "\", "")
        $fileContent = Get-Content -Path $filePath -Raw
        $wordCount = ($fileContent -split '\s+').Count
        $totalDataWords += $wordCount

        Add-Content -Path $outputFile -Value "`n--- File: $relativePath ---"
        Add-Content -Path $outputFile -Value "Words: $wordCount"

        # Special handling for CSV files
        if ($_.Extension -eq ".csv") {
            # Read first few lines of CSV for context
            $csvContent = Get-Content -Path $filePath -Raw | Select-Object -First 6
            Add-Content -Path $outputFile -Value "Content (first 5 rows):"
            Add-Content -Path $outputFile -Value ($csvContent | Out-String)
            Add-Content -Path $outputFile -Value "... (full content omitted for brevity)"
        } else {
            # For other data types, include full content
            Add-Content -Path $outputFile -Value $fileContent
        }
    }
}

# --- Update the metadata with the final word count ---
$finalContent = Get-Content -Path $outputFile -Raw
$metadataHeader = @"
===== Project Summary =====
Project Name: $projectName
Generation Date: $(Get-Timestamp)
Generated By: PowerShell Script
Total Source Code Words: $totalSourceCodeWords
Total Dataset/Text Words: $totalDataWords
Description: A comprehensive summary of the project's structure, source code, and data files, designed for secure LLM context submission.
===========================

"@
$finalContent = $finalContent.Replace("===== Project Summary =====
Project Name: universal-reconciliation-service
Generation Date: 2025-09-05 01:24:19
Generated By: PowerShell Script
Total Source Code Words: 6194
Total Dataset/Text Words: 16376
Description: A comprehensive summary of the project's structure, source code, and data files, designed for secure LLM context submission.
===========================
", $metadataHeader)
$finalContent | Set-Content -Path $outputFile

Write-Host "Project structure and source code have been saved to $outputFile"

===== Datasets and Text Files =====

--- File: package.json ---
Words: 91
{
  "name": "universal-reconciliation-service",
  "version": "1.0.0",
  "description": "A Universal Reconciliation Service API using Express and Gemini API, deployable to Netlify.",
  "main": "netlify/functions/api.js",
  "type": "commonjs",
  "scripts": {
    "start": "node src/api.js",
    "dev": "netlify dev",
    "deploy": "netlify deploy --prod",
    "test": "jest",
    "analyze": "python analysis/performance_analysis.py",
    "build": "echo 'No build needed for serverless functions'"
  },
  "keywords": [
    "reconciliation",
    "api",
    "openrefine",
    "gemini",
    "netlify",
    "serverless",
    "express"
  ],
  "author": "Google",
  "license": "MIT",
  "dependencies": {
    "@google/generative-ai": "^0.1.3",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "express": "^4.18.2",
    "serverless-http": "^3.2.0",
    "uuid": "^9.0.1",
    "winston": "^3.8.2"
  },
  "devDependencies": {
    "jest": "^29.7.0",
    "netlify-cli": "^23.5.0",
    "supertest": "^6.3.3"
  }
}


--- File: .netlify\state.json ---
Words: 35
{
	"geolocation": {
		"data": {
			"city": "Edinburgh",
			"country": {
				"code": "GB",
				"name": "United Kingdom"
			},
			"subdivision": {
				"code": "SCT",
				"name": "Scotland"
			},
			"timezone": "Europe/London",
			"latitude": 55.9632,
			"longitude": -3.2546,
			"postalCode": "EH4"
		},
		"timestamp": 1756827433493
	}
}

--- File: data\sample.json ---
Words: 15
[
  { "city": "Paris", "country": "France" },
  { "city": "London", "country": "UK" }
]


--- File: dataset\development\dev-famous-scientists.json ---
Words: 93
[
  { "name": "Albert Einstein", "query": "Einstein", "type": "person" },
  { "name": "Marie Curie", "query": "Curie", "type": "person" },
  { "name": "Isaac Newton", "query": "Newton", "type": "person" },
  { "name": "Galileo Galilei", "query": "Galileo", "type": "person" },
  { "name": "Nikola Tesla", "query": "Tesla", "type": "person" },
  { "name": "Charles Darwin", "query": "Darwin", "type": "person" },
  { "name": "Stephen Hawking", "query": "Hawking", "type": "person" },
  { "name": "Rosalind Franklin", "query": "Franklin", "type": "person" },
  { "name": "Alan Turing", "query": "Turing", "type": "person" },
  { "name": "Linus Pauling", "query": "Pauling", "type": "person" }
]


--- File: dataset\development\dev-landmarks.json ---
Words: 131
[
  { "name": "Eiffel Tower", "query": "Eiffel Tower", "type": "landmark" },
  { "name": "Statue of Liberty", "query": "Statue of Liberty", "type": "landmark" },
  { "name": "Great Wall of China", "query": "Great Wall of China", "type": "landmark" },
  { "name": "Colosseum", "query": "Colosseum", "type": "landmark" },
  { "name": "Taj Mahal", "query": "Taj Mahal", "type": "landmark" },
  { "name": "Pyramids of Giza", "query": "Pyramids of Giza", "type": "landmark" },
  { "name": "Machu Picchu", "query": "Machu Picchu", "type": "landmark" },
  { "name": "Christ the Redeemer", "query": "Christ the Redeemer", "type": "landmark" },
  { "name": "Stonehenge", "query": "Stonehenge", "type": "landmark" },
  { "name": "Burj Khalifa", "query": "Burj Khalifa", "type": "landmark" },
  { "name": "Sydney Opera House", "query": "Sydney Opera House", "type": "landmark" },
  { "name": "The Alamo", "query": "The Alamo", "type": "landmark" }
]


--- File: dataset\development\dev-major-cities.json ---
Words: 90
[
  { "name": "New York City", "query": "New York", "type": "city" },
  { "name": "Tokyo", "query": "Tokyo", "type": "city" },
  { "name": "London", "query": "London", "type": "city" },
  { "name": "Paris", "query": "Paris", "type": "city" },
  { "name": "Sydney", "query": "Sydney", "type": "city" },
  { "name": "Beijing", "query": "Beijing", "type": "city" },
  { "name": "Rio de Janeiro", "query": "Rio de Janeiro", "type": "city" },
  { "name": "Mumbai", "query": "Mumbai", "type": "city" },
  { "name": "Moscow", "query": "Moscow", "type": "city" },
  { "name": "Cairo", "query": "Cairo", "type": "city" }
]


--- File: dataset\development\dev-popular-movies.json ---
Words: 109
[
  { "name": "Inception", "query": "Inception", "type": "movie" },
  { "name": "The Godfather", "query": "The Godfather", "type": "movie" },
  { "name": "Pulp Fiction", "query": "Pulp Fiction", "type": "movie" },
  { "name": "The Dark Knight", "query": "The Dark Knight", "type": "movie" },
  { "name": "Forrest Gump", "query": "Forrest Gump", "type": "movie" },
  { "name": "The Shawshank Redemption", "query": "The Shawshank Redemption", "type": "movie" },
  { "name": "Fight Club", "query": "Fight Club", "type": "movie" },
  { "name": "The Matrix", "query": "The Matrix", "type": "movie" },
  { "name": "Goodfellas", "query": "Goodfellas", "type": "movie" },
  { "name": "The Silence of the Lambs", "query": "The Silence of the Lambs", "type": "movie" }
]


--- File: dataset\development\dev-tech-companies.json ---
Words: 87
[
  { "name": "Alphabet Inc.", "query": "Google" },
  { "name": "Apple Inc.", "query": "Apple" },
  { "name": "Microsoft Corp.", "query": "Microsoft" },
  { "name": "Amazon.com Inc.", "query": "Amazon" },
  { "name": "Meta Platforms, Inc.", "query": "Facebook", "type": "company" },
  { "name": "Tesla, Inc.", "query": "Tesla" },
  { "name": "Nvidia Corporation", "query": "Nvidia" },
  { "name": "Alibaba Group Holding Ltd.", "query": "Alibaba" },
  { "name": "Samsung Electronics Co., Ltd.", "query": "Samsung" },
  { "name": "Intel Corporation", "query": "Intel" },
  { "name": "Netflix, Inc.", "query": "Netflix" }
]


--- File: dataset\production\prod-ambiguous-entities.json ---
Words: 89
[
  { "name": "The Flash (DC Comics)", "query": "Flash" },
  { "name": "Taylor Swift", "query": "Taylor Swift" },
  { "name": "Tyler Swift", "query": "Tyler Swift" },
  { "name": "N.W.A.", "query": "NWA" },
  { "name": "Apple (Fruit)", "query": "Apple" },
  { "name": "The Eagles (band)", "query": "Eagles" },
  { "name": "Amazon River", "query": "Amazon" },
  { "name": "The Lord of the Rings: The Fellowship of the Ring", "query": "Fellowship of the Ring" },
  { "name": "Chicago Bulls", "query": "Bulls" },
  { "name": "Python (Programming Language)", "query": "Python" }
]


--- File: dataset\production\prod-financial-instruments.json ---
Words: 68
[
  { "name": "S&P 500 Index", "query": "Standard & Poor's 500" },
  { "name": "Dow Jones Industrial Average", "query": "Dow Jones" },
  { "name": "Bitcoin", "query": "Bitcoin", "type": "cryptocurrency" },
  { "name": "Ethereum", "query": "ETH", "type": "cryptocurrency" },
  { "name": "Treasury Bill", "query": "T-bill", "type": "security" },
  { "name": "Exchange-Traded Fund", "query": "ETF", "type": "investment" },
  { "name": "Mutual Fund", "query": "Mutual Fund", "type": "investment" }
]


--- File: dataset\production\prod-historical-events.json ---
Words: 102
[
  { "name": "World War II", "query": "WWII" },
  { "name": "The French Revolution", "query": "French Revolution" },
  { "name": "The Fall of the Berlin Wall", "query": "Berlin Wall Fall" },
  { "name": "The Renaissance", "query": "Renaissance" },
  { "name": "The Age of Enlightenment", "query": "Enlightenment" },
  { "name": "The American Civil War", "query": "Civil War" },
  { "name": "The invention of the printing press", "query": "Gutenberg printing press" },
  { "name": "The Space Race", "query": "Space Race" },
  { "name": "The first moon landing", "query": "moon landing" },
  { "name": "The Boston Tea Party", "query": "Boston Tea Party" }
]


--- File: dataset\production\prod-legal-precedents.json ---
Words: 60
[
  { "name": "Miranda v. Arizona", "query": "Miranda rights" },
  { "name": "Roe v. Wade", "query": "Roe v. Wade" },
  { "name": "Brown v. Board of Education", "query": "Brown vs Board", "type": "legal_case" },
  { "name": "Marbury v. Madison", "query": "judicial review case", "type": "legal_case" },
  { "name": "Plessy v. Ferguson", "query": "separate but equal", "type": "legal_case" }
]


--- File: dataset\production\prod-medical-diagnoses.json ---
Words: 75
[
  { "name": "Myocardial Infarction", "query": "heart attack" },
  { "name": "Hypertension", "query": "high blood pressure" },
  { "name": "Diabetes Mellitus Type 2", "query": "Type 2 diabetes" },
  { "name": "Alzheimer's Disease", "query": "Alzheimer's", "type": "neurological_condition" },
  { "name": "Schizophrenia", "query": "Schizophrenia", "type": "mental_health" },
  { "name": "Hepatitis C", "query": "Hepatitis C", "type": "disease" },
  { "name": "Tuberculosis", "query": "TB", "type": "infectious_disease" },
  { "name": "Osteoporosis", "query": "bone density loss", "type": "condition" }
]


--- File: dataset\production\prod-musical-artists.json ---
Words: 71
[
  { "name": "Taylor Swift", "query": "Taylor Swift" },
  { "name": "The Beatles", "query": "Beatles" },
  { "name": "Beyonc", "query": "Beyonce" },
  { "name": "Elvis Presley", "query": "Elvis" },
  { "name": "Michael Jackson", "query": "Michael Jackson" },
  { "name": "Queen", "query": "Queen" },
  { "name": "Led Zeppelin", "query": "Led Zeppelin" },
  { "name": "Eminem", "query": "Eminem" },
  { "name": "Adele", "query": "Adele" },
  { "name": "Drake", "query": "Drake" }
]


--- File: dataset\production\prod-professional-titles.json ---
Words: 49
[
  { "name": "Certified Public Accountant", "query": "CPA" },
  { "name": "Chief Executive Officer", "query": "CEO" },
  { "name": "Doctor of Medicine", "query": "MD" },
  { "name": "Juris Doctor", "query": "JD" },
  { "name": "Project Management Professional", "query": "PMP" },
  { "name": "Registered Nurse", "query": "RN" }
]


--- File: dataset\production\prod-scientific-terms.json ---
Words: 102
[
  { "name": "Quantum Entanglement", "query": "Quantum Entanglement", "type": "physics" },
  { "name": "Myocardial Infarction", "query": "heart attack", "type": "medical_condition" },
  { "name": "Neural Network", "query": "backpropagation algorithm", "type": "AI" },
  { "name": "RNA Splicing", "query": "RNA splicing", "type": "biology" },
  { "name": "General Relativity", "query": "theory of relativity", "type": "physics" },
  { "name": "Photosynthesis", "query": "photosynthesis", "type": "biology" },
  { "name": "Black Hole", "query": "black hole", "type": "astronomy" },
  { "name": "Cybersecurity Taxonomy (NIST)", "query": "NIST CSF", "type": "cybersecurity" },
  { "name": "Vulnerability Management", "query": "Vulnerability management", "type": "cybersecurity" },
  { "name": "Data Encryption", "query": "Cryptography", "type": "cybersecurity" }
]


--- File: dataset\production\prod-sports-teams.json ---
Words: 88
[
  { "name": "New York Yankees", "query": "Yankees" },
  { "name": "Los Angeles Lakers", "query": "Lakers" },
  { "name": "Real Madrid C.F.", "query": "Real Madrid" },
  { "name": "FC Barcelona", "query": "Barcelona" },
  { "name": "Manchester United F.C.", "query": "Manchester United" },
  { "name": "Boston Red Sox", "query": "Red Sox" },
  { "name": "Chicago Bulls", "query": "Chicago Bulls" },
  { "name": "Green Bay Packers", "query": "Green Bay Packers" },
  { "name": "Golden State Warriors", "query": "Golden State Warriors" },
  { "name": "Pittsburgh Steelers", "query": "Steelers" }
]


--- File: dataset\special\special-100-entries.json ---
Words: 147
[
  {
    "name": "Neural Network",
    "query": "A variant of backpropagation algorithm",
    "type": "AI"
  },
  {
    "name": "The Godfather",
    "query": "The Godfather"
  },
  {
    "name": "Apple Inc.",
    "query": "A variant of Apple"
  },
  {
    "name": "Sarbanes-Oxley Act",
    "query": "SOX Act",
    "type": "legal"
  },
  {
    "name": "Quantum Entanglement",
    "query": "quantum entanglement",
    "type": "physics"
  },
  {
    "name": "Albert Einstein",
    "query": "A variant of Einstein"
  },
  {
    "name": "Taylor Swift",
    "query": "Taylor Swift"
  },
  {
    "name": "Myocardial Infarction",
    "query": "heart attack",
    "type": "medical_condition"
  },
  {
    "name": "Microsoft Corp.",
    "query": "Microsooft"
  },
  {
    "name": "The Lord of the Rings: The Fellowship of the Ring",
    "query": "Fellowship of the Ring"
  },
  {
    "name": "Gross Domestic Product",
    "query": "A variant of GDP",
    "type": "economics"
  },
  {
    "name": "N.W.A.",
    "query": "NWA"
  },
  {
    "name": "Apple Inc.",
    "query": "Aapple"
  },
  {
    "name": "The Godfather",
    "query": "The Godfather"
  },
  {
    "name": "London",
    "query": "Loondon"
  }
]


--- File: all_code_dump.txt ---
Words: 1850
==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\api.js ====

const express = require('express');
const metadataRouter = require('./routes/metadata');
const reconcileRouter = require('./routes/reconcile');
const suggestEntityRouter = require('./routes/suggest-entity');
// ...other routers
const previewRouter = require('./routes/preview');
const extendProposeRouter = require('./routes/extend-propose');
const extendRouter = require('./routes/extend');
const streamChunkRouter = require('./routes/stream-chunk');

const app = express();
app.use(express.json());

// Enable CORS
app.use((req, res, next) => {
  res.set('Access-Control-Allow-Origin', '*');
  next();
});

// Mount routes
app.use('/metadata', metadataRouter);
app.use('/reconcile', reconcileRouter);
app.use('/suggest/entity', suggestEntityRouter);
app.use('/suggest/type', require('./routes/suggest-type'));
app.use('/suggest/property', require('./routes/suggest-property'));
app.use('/preview', previewRouter);
app.use('/extend/propose', extendProposeRouter);
app.use('/extend', extendRouter);
app.use('/stream-chunk', streamChunkRouter);

// Error middleware
app.use((err, req, res, next) => {
  console.error(err);
  res.status(err.status || 500).json({
    status: err.status || 500,
    error: err.name,
    message: err.message,
    timestamp: new Date().toISOString(),
  });
});

module.exports = app;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\swagger.js ====

const swaggerJsdoc = require('swagger-jsdoc');
const swaggerUi = require('swagger-ui-express');

const baseUrl = process.env.BASE_URL || 'http://localhost:8888';

const options = {
  definition: {
    openapi: '3.0.3',
    info: {
      title: 'Universal Reconciliation Service API',
      version: '1.0.0',
      description: 'API for reconciliation service using Express and Gemini API',
      contact: {
        name: 'Google',
        email: 'support@example.com',
      },
      license: {
        name: 'MIT',
        url: 'https://opensource.org/licenses/MIT',
      },
    },
    servers: [
      {
        url: baseUrl,
        description: 'Base URL of the API',
      },
    ],
  },
  apis: ['./netlify/functions/routes/*.js'],
};

const swaggerSpec = swaggerJsdoc(options);

function setupSwagger(app) {
  app.use('/api-docs', swaggerUi.serve, swaggerUi.setup(swaggerSpec));
}

module.exports = setupSwagger;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\utils.js ====

const { GoogleGenerativeAI } = require('@google/generative-ai');
const { v4: uuidv4 } = require('uuid');
const path = require('path');
const fs = require('fs');
require('dotenv').config();

const API_KEY = proceupdatess.env.GEMINI_API_KEY;
if (!API_KEY) {
  console.error("GEMINI_API_KEY is not set. Please set the environment variable.");
  process.exit(1);
}
const genAI = new GoogleGenerativeAI(API_KEY);

// Helper function to get the Gemini model response
async function getModelResponse(prompt, isJson, useSearch) {
  try {
    const generationConfig = isJson ? { responseMimeType: "application/json" } : {};
    const tools = useSearch ? [{ google_search: {} }] : undefined;

    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash-preview-05-20", generationConfig, tools });

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    return { text };
  } catch (error) {
    console.error('Gemini API error:', error);
    throw new Error('Failed to get response from Gemini API.');
  }
}

// Helper function to get service metadata
function getServiceMetadata() {
  return {
    name: "Universal Reconciliation Service API",
    identifierSpace: "[http://www.freebase.com/ns/freebase](http://www.freebase.com/ns/freebase)",
    schemaSpace: "[http://www.freebase.com/ns/type.type](http://www.freebase.com/ns/type.type)",
    view: {
      url: "{{id}}"
    },
    defaultTypes: [{
      id: "/common/topic",
      name: "Topic"
    }],
    reconcile: {
      path: "/reconcile",
      serviceUrl: "/.netlify/functions/api"
    },
    suggest: {
      entity: {
        path: "/suggest/entity",
        serviceUrl: "/.netlify/functions/api"
      },
      type: {
        path: "/suggest/type",
        serviceUrl: "/.netlify/functions/api"
      },
      property: {
        path: "/suggest/property",
        serviceUrl: "/.netlify/functions/api"
      }
    },
    preview: {
      path: "/preview",
      serviceUrl: "/.netlify/functions/api"
    },
    extend: {
      propose_properties: {
        path: "/extend/propose",
        serviceUrl: "/.netlify/functions/api"
      },
      serviceUrl: "/.netlify/functions/api"
    }
  };
}

// Helper function to handle reconciliation matching
async function getMatchingResults(queries) {
  const results = {};
  for (const qid in queries) {
    const query = queries[qid];
    const userPrompt = `Reconcile the entity "${query.query}" against entities of type "${query.type}". Provide a list of 5 possible matches in JSON format, each with a 'name', 'id', 'score' (0-100), and 'type' property. The 'score' should reflect the confidence of the match.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const matches = JSON.parse(modelResponse.text);

    results[qid] = {
      result: matches.map(match => ({
        id: match.id || uuidv4(),
        name: match.name,
        score: match.score / 100,
        match: match.score > 70 ? true : false,
        type: [{
          id: match.type,
          name: match.type
        }]
      }))
    };
  }
  return results;
}

// Helper function to handle suggestions
async function getSuggestions(type, prefix) {
  let userPrompt;
  switch (type) {
    case 'entity':
      userPrompt = `Suggest 5 entities related to "${prefix}" in JSON format. Each entity should have a 'name' and 'id'.`;
      break;
    case 'type':
      userPrompt = `Suggest 5 data types related to "${prefix}" in JSON format. Each type should have a 'name' and 'id'.`;
      break;
    case 'property':
      userPrompt = `Suggest 5 properties that start with "${prefix}" in JSON format. Each property should have a 'name' and 'id'.`;
      break;
    default:
      throw new Error(`Invalid suggestion type: ${type}`);
  }

  const modelResponse = await getModelResponse(userPrompt, true, false);
  const suggestions = JSON.parse(modelResponse.text);

  return {
    result: suggestions.map(s => ({
      id: s.id || uuidv4(),
      name: s.name,
      description: s.description || ""
    }))
  };
}

// Helper function to get preview HTML
async function getPreviewHTML(id) {
  const userPrompt = `Generate a short HTML description for an entity with the ID "${id}". Make sure the HTML is well-formed.`;
  const modelResponse = await getModelResponse(userPrompt, true, false);
  return modelResponse.text;
}

// Helper function to get extended properties
async function getExtendedProperties(ids, properties) {
  const data = {};
  for (const id of ids) {
    const userPrompt = `For the entity with ID "${id}", retrieve the values for the following properties: ${properties.map(p => p.id).join(', ')}. Provide the result in a JSON object where keys are the property IDs and values are the corresponding values.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const values = JSON.parse(modelResponse.text);
    data[id] = values;
  }
  return {
    meta: properties.map(p => ({ id: p.id, name: p.name })),
    rows: ids.map(id => ({ id: id, values: properties.map(p => data[id][p.id] ? [{ str: data[id][p.id] }] : []) }))
  };
}


module.exports = {
  getServiceMetadata,
  getModelResponse,
  getMatchingResults,
  getSuggestions,
  getPreviewHTML,
  getExtendedProperties,
};




==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\extend-propose.js ====

/**
 * @swagger
 * /extend-propose:
 *   get:
 *     summary: Example GET endpoint for extend-propose
 *     description: Detailed description for the extend-propose endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const { v4: uuidv4 } = require('uuid');

// Extend Propose Route
// This endpoint proposes properties for data extension.
router.post('/', async (req, res) => {
  try {
    const type = req.body.type;
    const userPrompt = `Propose 5 properties to extend data for the entity type "${type}". Provide the suggestions in JSON format. Each property should have an 'id' and 'name'.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const properties = JSON.parse(modelResponse.text);

    res.status(200).json({
      properties: properties.map(p => ({
        id: p.id || uuidv4(),
        name: p.name
      }))
    });
  } catch (error) {
    console.error('Extend propose error:', error);
    res.status(500).json({ error: 'Failed to propose properties.' });
  }
});

module.exports = router;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\extend.js ====

/**
 * @swagger
 * /extend:
 *   get:
 *     summary: Example GET endpoint for extend
 *     description: Detailed description for the extend endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');

// Extend Route
// This endpoint extends data by adding properties to entities.
router.post('/', async (req, res) => {
  try {
    const ids = req.body.ids;
    const properties = req.body.properties;

    if (!ids || !properties || !Array.isArray(ids) || !Array.isArray(properties)) {
      return res.status(400).json({ error: 'Missing or invalid ids or properties.' });
    }

    const data = {};
    for (const id of ids) {
      const userPrompt = `For the entity with ID "${id}", retrieve the values for the following properties: ${properties.map(p => p.id).join(', ')}. Provide the result in a JSON object where keys are the property IDs and values are the corresponding values.`;
      const modelResponse = await getModelResponse(userPrompt, true, false);

      const values = JSON.parse(modelResponse.text);
      data[id] = values;
    }

    res.status(200).json({
      meta: properties.map(p => ({ id: p.id, name: p.name })),
      rows: ids.map(id => ({ id: id, values: properties.map(p => data[id][p.id] ? [{ str: data[id][p.id] }] : []) }))
    });
  } catch (error) {
    console.error('Extend error:', error);
    res.status(500).json({ error: 'Failed to extend data.' });
  }
});

module.exports = router;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\metadata.js ====

/**
 * @swagger
 * /metadata:
 *   get:
 *     summary: Example GET endpoint for metadata
 *     description: Detailed description for the metadata endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
// src/routes/metadata.js
const express = require('express');
const router = express.Router();

router.get('/', (req, res) => {
  const baseUrl = `${req.protocol}://${req.get('host')}`;
  res.json({
    name: 'Universal Reconciliation Service',
    identifierSpace: 'http://example.com/identifiers',
    schemaSpace: 'http://example.com/schemas',
    defaultTypes: [{ id: '/general', name: 'General Entity' }],
    view: { url: 'http://example.com/view/{{id}}' },
    preview: {
      url: `${baseUrl}/preview?id={{id}}`,
      width: 400,
      height: 200,
    },
    suggest: {
      entity: { service_url: baseUrl, service_path: '/suggest/entity' },
      type: { service_url: baseUrl, service_path: '/suggest/type' },
      property: { service_url: baseUrl, service_path: '/suggest/property' },
    },
    extend: {
      propose_properties: { service_url: baseUrl, service_path: '/extend/propose' },
      property_settings: [
        {
          name: 'maxItems',
          label: 'Maximum number of values',
          type: 'number',
          default: 1,
        },
      ],
    },
  });
});

module.exports = router;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\preview.js ====

/**
 * @swagger
 * /preview:
 *   get:
 *     summary: Example GET endpoint for preview
 *     description: Detailed description for the preview endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');

// Preview Route
// This endpoint generates a preview of an entity.
router.get('/', async (req, res) => {
  try {
    const id = req.query.id;
    if (!id) {
      return res.status(400).send('Entity ID is required.');
    }

    const userPrompt = `Generate a short HTML description for an entity with the ID "${id}". Make sure the HTML is well-formed.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const htmlContent = modelResponse.text;

    res.status(200).send(htmlContent);
  } catch (error) {
    console.error('Preview error:', error);
    res.status(500).send('Failed to generate preview.');
  }
});

module.exports = router;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\stream-chunk.js ====

/**
 * @swagger
 * /stream-chunk:
 *   get:
 *     summary: Example GET endpoint for stream-chunk
 *     description: Detailed description for the stream-chunk endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const path = require('path');
const fs = require('fs');

// Stream Chunk Route
// This endpoint handles real-time stream chunk matching.
router.post('/', async (req, res) => {
  try {
    const { input, fileName } = req.body;
    if (!input || !fileName) {
      return res.status(400).json({ error: 'Input text and file name are required.' });
    }

    const filePath = path.join(__dirname, '..', '..', 'data', fileName);
    if (!fs.existsSync(filePath)) {
      return res.status(404).json({ error: 'File not found.' });
    }

    const fileContent = fs.readFileSync(filePath, 'utf-8');
    const userPrompt = `Given the input chunk "${input}" and the following data:\n\n---\n${fileContent}\n---\n\nDetermine the best match from the data for the input chunk. Provide a JSON object with 'match' and 'confidence' (0-100) properties. If no match is found, set 'match' to null.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const result = JSON.parse(modelResponse.text);

    res.status(200).json({
      match: result.match,
      confidence: result.confidence / 100
    });
  } catch (error) {
    console.error('Stream chunk error:', error);
    res.status(500).json({ error: 'Failed to process stream chunk.' });
  }
});

module.exports = router;




==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\suggest-property.js ====

/**
 * @swagger
 * /suggest-property:
 *   get:
 *     summary: Example GET endpoint for suggest-property
 *     description: Detailed description for the suggest-property endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const { v4: uuidv4 } = require('uuid');

// Suggest Property Route
// This endpoint suggests properties based on a query.
router.get('/', async (req, res) => {
  try {
    const query = req.query.prefix;
    const type = req.query.type;
    if (!query) {
      return res.status(400).json({ error: 'Query prefix is required.' });
    }

    let userPrompt;
    if (type) {
      userPrompt = `Suggest 5 properties for a data type named "${type}" that start with "${query}". Provide the suggestions in JSON format, each with a 'name' and 'id'.`;
    } else {
      userPrompt = `Suggest 5 properties that start with "${query}" in JSON format. Each property should have a 'name' and 'id'.`;
    }
    
    const modelResponse = await getModelResponse(userPrompt, true, false);
    const suggestions = JSON.parse(modelResponse.text);

    res.status(200).json({
      result: suggestions.map(s => ({
        id: s.id || uuidv4(),
        name: s.name
      }))
    });
  } catch (error) {
    console.error('Suggest property error:', error);
    res.status(500).json({ error: 'Failed to get property suggestions.' });
  }
});

module.exports = router;





--- File: project-audit-report.txt ---
Words: 96
==== Project Audit Report - 09/02/2025 17:13:39 ====

>> Checking required directories:
  [OK] Directory exists: netlify/functions
  [OK] Directory exists: netlify/functions/routes
  [OK] Directory exists: src/routes
  [OK] Directory exists: analysis
  [OK] Directory exists: data
  [OK] Directory exists: dataset/development
  [OK] Directory exists: dataset/production
  [OK] Directory exists: dataset/special
  [OK] Directory exists: public
  [OK] Directory exists: scripts
  [OK] Directory exists: tests


>> Checking required files:
  [OK] File exists: netlify/functions/api.js
  [OK] File exists: src/swagger.js
  [OK] File exists: package.json


>> Syntax check for JS files:
Checking file: netlify/functions/api.js
Status: Syntax OK

Checking file: src/swagger.js
Status: Syntax OK

==== End of Report ====


--- File: universal-reconciliation-service_ProjectSummary.txt ---
Words: 9960
===== Project Summary =====
Project Name: universal-reconciliation-service
Generation Date: 2025-09-05 01:24:19
Generated By: PowerShell Script
Total Source Code Words: 6194
Total Dataset/Text Words: 16376
Description: A comprehensive summary of the project's structure, source code, and data files, designed for secure LLM context submission.
===========================

===== Directory Structure =====
all_code_dump.txt
netlify.toml
package.json
project-audit-report.txt
project_analysis_script.ps1
README.md
test_reconciliation.js
test_reconciliation.py
universal-reconciliation-service_ProjectSummary.txt
.netlify\state.json
analysis\performance_analysis.py
data\sample.json
data\sample.txt
dataset\development\dev-famous-scientists.json
dataset\development\dev-landmarks.json
dataset\development\dev-major-cities.json
dataset\development\dev-popular-movies.json
dataset\development\dev-tech-companies.json
dataset\production\prod-ambiguous-entities.json
dataset\production\prod-financial-instruments.json
dataset\production\prod-historical-events.json
dataset\production\prod-legal-precedents.json
dataset\production\prod-medical-diagnoses.json
dataset\production\prod-musical-artists.json
dataset\production\prod-professional-titles.json
dataset\production\prod-scientific-terms.json
dataset\production\prod-sports-teams.json
dataset\special\special-100-entries.json
netlify\functions\api.js
netlify\functions\api.js.bak
netlify\functions\extend-propose.js
netlify\functions\extend.js
netlify\functions\metadata.js
netlify\functions\preview.js
netlify\functions\reconcile.js
netlify\functions\stream-chunk.js
netlify\functions\suggest-entity.js
netlify\functions\suggest-property.js
netlify\functions\suggest-type.js
netlify\functions\utils.js
public\index.html
scripts\dataset_generator.py
src\api.js
src\swagger.js
src\utils.js
src\routes\extend-propose.js
src\routes\extend.js
src\routes\metadata.js
src\routes\preview.js
src\routes\stream-chunk.js
src\routes\suggest-property.js
tests\accuracy.test.js
tests\performance.test.js
tests\stream.test.js


===== Source Code Files =====

--- File: test_reconciliation.py ---
Words: 451
import os
import json
import requests
from typing import Dict, List, Any

# --- Configuration ---
# Set the base URL for your reconciliation service here.
# NOTE: This is a placeholder. You must replace it with the actual URL of your service.
SERVICE_URL = "http://localhost:5000/reconcile"
DATASET_DIR = "dataset"
PRODUCTION_DIR = os.path.join(DATASET_DIR, "production")
DEVELOPMENT_DIR = os.path.join(DATASET_DIR, "development")

def run_reconciliation_test(file_path: str, service_url: str):
    """
    Loads a JSON dataset, sends reconciliation queries, and prints the results.

    Args:
        file_path (str): The path to the JSON dataset file.
        service_url (str): The URL of the reconciliation service endpoint.
    """
    print(f"\n--- Testing dataset: {os.path.basename(file_path)} ---")
    
    # Load the test data from the JSON file.
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            test_data = json.load(f)
    except FileNotFoundError:
        print(f"ERROR: File not found at {file_path}")
        return
    except json.JSONDecodeError:
        print(f"ERROR: Invalid JSON in file at {file_path}")
        return

    # Prepare a list of queries for the API call.
    queries: Dict[str, Dict[str, str]] = {}
    for i, item in enumerate(test_data):
        # We use a unique key for each query (e.g., "q0", "q1", ...)
        queries[f"q{i}"] = {"query": item.get("query", "")}

    # Construct the payload for the POST request.
    payload = {"queries": json.dumps(queries)}

    # Send the request to the reconciliation service.
    try:
        response = requests.post(service_url, data=payload)
        response.raise_for_status()  # Raises an HTTPError for bad responses (4xx or 5xx)
        api_results: Dict[str, Any] = response.json()
    except requests.exceptions.RequestException as e:
        print(f"ERROR: Failed to connect to service at {service_url}. Please ensure the service is running.")
        print(f"Exception: {e}")
        return
    except json.JSONDecodeError:
        print("ERROR: Invalid JSON response from the API.")
        print("Response content:", response.text)
        return

    # Process and validate the results.
    for i, item in enumerate(test_data):
        query_key = f"q{i}"
        
        # Check if the API returned a result for this query.
        if query_key not in api_results:
            print(f"FAIL: '{item['query']}' - No result found for query key '{query_key}'")
            continue

        query_result = api_results[query_key].get("result", [])
        
        # Check if the result list is not empty.
        if not query_result:
            print(f"FAIL: '{item['query']}' - Result list is empty")
            continue

        # Simple validation: Check if the top candidate's name matches the expected name.
        top_candidate = query_result[0]
        reconciled_name = top_candidate.get("name", "")
        expected_name = item.get("name", "")

        # A successful match.
        if reconciled_name == expected_name:
            print(f"SUCCESS: '{item['query']}' -> '{reconciled_name}'")
        else:
            print(f"FAIL: '{item['query']}' - Expected '{expected_name}', got '{reconciled_name}'")

def main():
    """
    Main function to discover and run all test scripts.
    """
    print("Starting reconciliation service test suite...")
    print("------------------------------------------")

    # Get a list of all JSON files in the development and production directories.
    all_files = []
    if os.path.exists(DEVELOPMENT_DIR):
        for filename in os.listdir(DEVELOPMENT_DIR):
            if filename.endswith(".json"):
                all_files.append(os.path.join(DEVELOPMENT_DIR, filename))
    
    if os.path.exists(PRODUCTION_DIR):
        for filename in os.listdir(PRODUCTION_DIR):
            if filename.endswith(".json"):
                all_files.append(os.path.join(PRODUCTION_DIR, filename))
    
    if not all_files:
        print("No test dataset files found. Please run the generation scripts first.")
        return

    # Run the tests for each discovered file.
    for file in all_files:
        run_reconciliation_test(file, SERVICE_URL)

if __name__ == "__main__":
    main()


--- File: analysis\performance_analysis.py ---
Words: 157
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ttest_ind

# Sample data (replace with actual test results)
latencies = {
    'reconcile': [150, 200, 180, 220, 190, 210, 170, 230, 195, 205],
    'stream_chunk': [120, 130, 140, 110, 150, 125, 135, 145, 115, 130]
}
accuracies = {
    'reconcile': [0.95, 0.90, 0.92, 0.88, 0.94, 0.91, 0.89, 0.93, 0.90, 0.92],
    'stream_chunk': [0.85, 0.87, 0.90, 0.88, 0.86, 0.89, 0.87, 0.88, 0.86, 0.90]
}

# Statistical significance
reconcile_lat = latencies['reconcile']
stream_lat = latencies['stream_chunk']
t_stat_lat, p_value_lat = ttest_ind(reconcile_lat, stream_lat)
print(f"Latency T-test: t={t_stat_lat:.2f}, p={p_value_lat:.4f}")

reconcile_acc = accuracies['reconcile']
stream_acc = accuracies['stream_chunk']
t_stat_acc, p_value_acc = ttest_ind(reconcile_acc, stream_acc)
print(f"Accuracy T-test: t={t_stat_acc:.2f}, p={p_value_acc:.4f}")

# Visualizations
df_lat = pd.DataFrame({'Reconcile': reconcile_lat, 'Stream Chunk': stream_lat})
df_acc = pd.DataFrame({'Reconcile': accuracies['reconcile'], 'Stream Chunk': accuracies['stream_chunk']})

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
sns.boxplot(data=df_lat)
plt.title('Latency Distribution (ms)')
plt.ylabel('Latency (ms)')
plt.subplot(1, 2, 2)
sns.boxplot(data=df_acc)
plt.title('Accuracy Distribution')
plt.ylabel('Accuracy')
plt.savefig('performance.png')
plt.show()

# Summary statistics
print("
Latency Summary:")
print(df_lat.describe())
print("
Accuracy Summary:")
print(df_acc.describe())


--- File: scripts\dataset_generator.py ---
Words: 605
import json
import random
import os

def create_dataset_dir(env):
    """Ensures the dataset directory exists."""
    os.makedirs(f'../dataset/{env}', exist_ok=True)

def generate_mock_data(size=100):
    """Generates a large mock dataset for testing purposes."""
    dataset = []
    
    # Core entities
    core_entities = [
        {"name": "Apple Inc.", "query": "Apple"},
        {"name": "Microsoft Corp.", "query": "Microsoft"},
        {"name": "London", "query": "London"},
        {"name": "Albert Einstein", "query": "Einstein"},
        {"name": "The Godfather", "query": "Godfather"},
    ]

    # Expert Knowledge (Critical Fields)
    expert_entities = [
        {"name": "Myocardial Infarction", "query": "heart attack", "type": "medical_condition"},
        {"name": "Neural Network", "query": "backpropagation algorithm", "type": "AI"},
        {"name": "Quantum Entanglement", "query": "quantum entanglement", "type": "physics"},
        {"name": "Sarbanes-Oxley Act", "query": "SOX Act", "type": "legal"},
        {"name": "Gross Domestic Product", "query": "GDP", "type": "economics"},
    ]

    # Special Cases (Fine-Tuning)
    special_cases = [
        {"name": "The Flash (DC Comics)", "query": "Flash"},
        {"name": "Taylor Swift", "query": "Taylor Swift"},
        {"name": "Tyler Swift", "query": "Tyler Swift"},
        {"name": "The Lord of the Rings: The Fellowship of the Ring", "query": "Fellowship of the Ring"},
        {"name": "N.W.A.", "query": "NWA"}
    ]

    # Combine all data sources to create a rich dataset
    data_sources = [core_entities, expert_entities, special_cases]

    # Generate the requested number of data points
    for i in range(size):
        # Select a random entity type from our data sources
        source = random.choice(data_sources)
        item = random.choice(source).copy()

        # Introduce some variation (e.g., misspellings, new queries)
        if i % 5 == 0:
            item["query"] = f"A variant of {item['query']}"
        elif i % 7 == 0:
            item["query"] = item["query"].replace('e', 'ee').replace('a', 'aa')
        
        dataset.append(item)
    import json
import random
import os

def create_dataset_dir(env):
    """Ensures the dataset directory exists."""
    os.makedirs(f'../dataset/{env}', exist_ok=True)

def generate_mock_data(size=100):
    """Generates a large mock dataset for testing purposes."""
    dataset = []
    
    # Core entities
    core_entities = [
        {"name": "Apple Inc.", "query": "Apple"},
        {"name": "Microsoft Corp.", "query": "Microsoft"},
        {"name": "London", "query": "London"},
        {"name": "Albert Einstein", "query": "Einstein"},
        {"name": "The Godfather", "query": "Godfather"},
    ]

    # Expert Knowledge (Critical Fields)
    expert_entities = [
        {"name": "Myocardial Infarction", "query": "heart attack", "type": "medical_condition"},
        {"name": "Neural Network", "query": "backpropagation algorithm", "type": "AI"},
        {"name": "Quantum Entanglement", "query": "quantum entanglement", "type": "physics"},
        {"name": "Sarbanes-Oxley Act", "query": "SOX Act", "type": "legal"},
        {"name": "Gross Domestic Product", "query": "GDP", "type": "economics"},
    ]

    # Special Cases (Fine-Tuning)
    special_cases = [
        {"name": "The Flash (DC Comics)", "query": "Flash"},
        {"name": "Taylor Swift", "query": "Taylor Swift"},
        {"name": "Tyler Swift", "query": "Tyler Swift"},
        {"name": "The Lord of the Rings: The Fellowship of the Ring", "query": "Fellowship of the Ring"},
        {"name": "N.W.A.", "query": "NWA"}
    ]

    # Combine all data sources to create a rich dataset
    data_sources = [core_entities, expert_entities, special_cases]

    # Generate the requested number of data points
    for i in range(size):
        # Select a random entity type from our data sources
        source = random.choice(data_sources)
        item = random.choice(source).copy()

        # Introduce some variation (e.g., misspellings, new queries)
        if i % 5 == 0:
            item["query"] = f"A variant of {item['query']}"
        elif i % 7 == 0:
            item["query"] = item["query"].replace('e', 'ee').replace('a', 'aa')
        
        dataset.append(item)
    
    return dataset

def save_dataset(dataset, filename, env):
    """Saves the dataset to a JSON file in the specified environment directory."""
    create_dataset_dir(env)
    file_path = f'../dataset/{env}/{filename}.json'
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, indent=2)
    print(f"Saved {len(dataset)} items to {file_path}")

if __name__ == "__main__":
    # Generate a rich and diverse special dataset with 100 entries
    special_data = generate_mock_data(size=100)
    save_dataset(special_data, 'special-100-entries', 'special')

    # Example for other environments (e.g., development)
    # dev_data = generate_mock_data(size=100)
    # save_dataset(dev_data, 'dev-100-entries', 'development')
    

    return dataset

def save_dataset(dataset, filename, env):
    """Saves the dataset to a JSON file in the specified environment directory."""
    create_dataset_dir(env)
    file_path = f'../dataset/{env}/{filename}.json'
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, indent=2)
    print(f"Saved {len(dataset)} items to {file_path}")

if __name__ == "__main__":
    # Generate a rich and diverse special dataset with 100 entries
    special_data = generate_mock_data(size=100)
    save_dataset(special_data, 'special-100-entries', 'special')

    # Example for other environments (e.g., development)
    # dev_data = generate_mock_data(size=100)
    # save_dataset(dev_data, 'dev-100-entries', 'development')
    


--- File: test_reconciliation.js ---
Words: 521
import { promises as fs } from 'fs';
import path from 'path';

// --- Configuration ---
// Set the base URL for your reconciliation service here.
// NOTE: This is a placeholder. You must replace it with the actual URL of your service.
const SERVICE_URL = "http://localhost:5000/reconcile";
const DATASET_DIR = "dataset";
const PRODUCTION_DIR = path.join(DATASET_DIR, "production");
const DEVELOPMENT_DIR = path.join(DATASET_DIR, "development");

/**
 * Loads a JSON dataset, sends reconciliation queries, and prints the results.
 *
 * @param {string} filePath The path to the JSON dataset file.
 * @param {string} serviceUrl The URL of the reconciliation service endpoint.
 */
async function runReconciliationTest(filePath, serviceUrl) {
    console.log(\n--- Testing dataset: \ ---);

    let testData;
    // Load the test data from the JSON file.
    try {
        const fileContent = await fs.readFile(filePath, 'utf-8');
        testData = JSON.parse(fileContent);
    } catch (error) {
        if (error.code === 'ENOENT') {
            console.error(ERROR: File not found at \);
        } else {
            console.error(ERROR: Invalid JSON in file at \);
            console.error(error.message);
        }
        return;
    }

    // Prepare a list of queries for the API call.
    const queries = {};
    testData.forEach((item, i) => {
        // We use a unique key for each query (e.g., "q0", "q1", ...)
        queries[q\] = { "query": item.query || "" };
    });

    // Send the request to the reconciliation service.
    try {
        const response = await fetch(serviceUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ queries: JSON.stringify(queries) })
        });

        if (!response.ok) {
            throw new Error(HTTP error! Status: \);
        }

        const apiResults = await response.json();

        // Process and validate the results.
        testData.forEach((item, i) => {
            const queryKey = q\;
            
            // Check if the API returned a result for this query.
            if (!apiResults[queryKey]) {
                console.log(FAIL: '\' - No result found for query key '\');
                return;
            }

            const queryResult = apiResults[queryKey].result || [];
            
            // Check if the result list is not empty.
            if (queryResult.length === 0) {
                console.log(FAIL: '\' - Result list is empty);
                return;
            }

            // Simple validation: Check if the top candidate's name matches the expected name.
            const topCandidate = queryResult[0];
            const reconciledName = topCandidate.name || "";
            const expectedName = item.name || "";

            // A successful match.
            if (reconciledName === expectedName) {
                console.log(SUCCESS: '\' -> '\');
            } else {
                console.log(FAIL: '\' - Expected '\', got '\');
            }
        });

    } catch (error) {
        console.error(ERROR: Failed to connect to service at \. Please ensure the service is running.);
        console.error(Exception: \);
    }
}

async function main() {
    console.log("Starting reconciliation service test suite...");
    console.log("------------------------------------------");

    const allFiles = [];

    // Get a list of all JSON files in the development and production directories.
    try {
        if (await fs.stat(DEVELOPMENT_DIR).then(() => true).catch(() => false)) {
            const devFiles = (await fs.readdir(DEVELOPMENT_DIR)).filter(filename => filename.endsWith(".json"));
            allFiles.push(...devFiles.map(file => path.join(DEVELOPMENT_DIR, file)));
        }
    } catch (e) { /* directory does not exist */ }

    try {
        if (await fs.stat(PRODUCTION_DIR).then(() => true).catch(() => false)) {
            const prodFiles = (await fs.readdir(PRODUCTION_DIR)).filter(filename => filename.endsWith(".json"));
            allFiles.push(...prodFiles.map(file => path.join(PRODUCTION_DIR, file)));
        }
    } catch (e) { /* directory does not exist */ }

    if (allFiles.length === 0) {
        console.log("No test dataset files found. Please run the generation scripts first.");
        return;
    }

    // Run the tests for each discovered file.
    for (const file of allFiles) {
        await runReconciliationTest(file, SERVICE_URL);
    }
}

main();


--- File: netlify\functions\api.js ---
Words: 231
const express = require('express');
const cors = require('cors');
const bodyParser = require('body-parser');
const path = require('path');

const app = express();

// Middleware
app.use(cors());
app.use(bodyParser.json());
app.use(bodyParser.urlencoded({ extended: true }));


const baseUrl = process.env.BASE_URL || 'http://localhost:8888';

  definition: {
    openapi: '3.0.3',
    info: {
      title: 'Universal Reconciliation Service API',
      version: '1.0.0',
      description: 'API for reconciliation service using Express and Gemini API',
      contact: { name: 'Google', email: 'support@example.com' },
      license: { name: 'MIT', url: 'https://opensource.org/licenses/MIT' },
    },
    servers: [{ url: baseUrl, description: 'API base URL' }],
  },
  apis: [path.join(__dirname, 'routes', '*.js')],
};


  res.setHeader('Content-Type', 'application/json');
});

// Import your route handlers
const reconcileRouter = require('./routes/reconcile');
const metadataRouter = require('./routes/metadata');
const previewRouter = require('./routes/preview');
const suggestRouter = require('./routes/suggest-entity');
const suggestPropertyRouter = require('./routes/suggest-property');
const suggestTypeRouter = require('./routes/suggest-type');
const extendRouter = require('./routes/extend');
const extendProposeRouter = require('./routes/extend-propose');
const streamChunkRouter = require('./routes/stream-chunk');

// Register routes
app.use('/', metadataRouter);
app.use('/reconcile', reconcileRouter);
app.use('/preview', previewRouter);
app.use('/suggest/entity', suggestRouter);
app.use('/suggest/property', suggestPropertyRouter);
app.use('/suggest/type', suggestTypeRouter);
app.use('/extend', extendRouter);
app.use('/extend/propose', extendProposeRouter);
app.use('/stream-chunk', streamChunkRouter);

// Catch-all 404 for unknown routes
app.use((req, res, next) => {
  res.status(404).json({
    error: 'Not Found',
    message: `The requested URL ${req.originalUrl} was not found on this server.`,
  });
});

// Global error handler (production ready)
app.use((err, req, res, next) => {
  console.error('Server error:', err.stack || err);

  // Customize error response based on environment
  const response = {
    error: 'Internal Server Error',
  };

  if (process.env.NODE_ENV !== 'production') {
    response.message = err.message;
    response.stack = err.stack;
  }

  res.status(500).json(response);
});

module.exports = app;


--- File: netlify\functions\extend-propose.js ---
Words: 120
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { type = '', limit = 10 } = JSON.parse(event.body || '{}');
    const prompt = Propose properties for type "", limit to . Return as JSON with properties array of {id, name}.;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        properties: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Propose properties error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ properties: [] }),
    };
  }
};


--- File: netlify\functions\extend.js ---
Words: 147
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { ids = [], properties = [] } = JSON.parse(event.body || '{}');
    const results = { rows: {} };

    for (const id of ids) {
      const prompt = Extend data for entity ID "" with properties: . Return as JSON with values for each property as array of {str or num}.;
      const llmResponse = await callGemini(prompt, {
        type: "object",
        properties: properties.reduce((acc, prop) => ({
          ...acc,
          [prop.id]: {
            type: "array",
            items: { type: "object", properties: { str: { type: "string" }, num: { type: "number" } } },
          },
        }), {}),
      });
      results.rows[id] = llmResponse;
    }

    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(results),
    };
  } catch (error) {
    console.error('Extend error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ rows: {} }),
    };
  }
};


--- File: netlify\functions\metadata.js ---
Words: 117
exports.handler = async (event, context) => {
  // Use environment variable BASE_URL or fallback to localhost
  const baseUrl = process.env.BASE_URL || "http://localhost:8888";

  return {
    statusCode: 200,
    headers: { "Access-Control-Allow-Origin": "*" },
    body: JSON.stringify({
      name: "Universal Reconciliation Service",
      identifierSpace: "http://example.com/identifiers",
      schemaSpace: "http://example.com/schemas",
      defaultTypes: [{ id: "/general", name: "General Entity" }],
      view: { url: "http://example.com/view/{{id}}" },
      preview: { url: `${baseUrl}/preview?id={{id}}`, width: 400, height: 200 },
      suggest: {
        entity: { service_url: baseUrl, service_path: "/suggest/entity" },
        type: { service_url: baseUrl, service_path: "/suggest/type" },
        property: { service_url: baseUrl, service_path: "/suggest/property" },
      },
      extend: {
        propose_properties: { service_url: baseUrl, service_path: "/extend/propose" },
        property_settings: [
          { name: "maxItems", label: "Maximum number of values", type: "number", default: 1 },
        ],
      },
    }),
  };
};


--- File: netlify\functions\preview.js ---
Words: 98
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { id = '' } = event.queryStringParameters;
    const prompt = Generate a preview for entity with ID "". Return as JSON with html containing the preview content.;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: { html: { type: "string" } },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Preview error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ html: '<p>Error generating preview</p>' }),
    };
  }
};


--- File: netlify\functions\reconcile.js ---
Words: 113
const { callGemini, getReconcileSchema } = require('./utils');

exports.handler = async (event) => {
  try {
    const queries = JSON.parse(event.body?.queries || event.queryStringParameters?.queries || '{}');
    const callback = event.queryStringParameters?.callback;
    const results = {};

    for (const [key, query] of Object.entries(queries)) {
      const prompt = Reconcile query: , Type: , Limit: , Properties: ;
      const llmResponse = await callGemini(prompt, getReconcileSchema());
      results[key] = { result: llmResponse.result || [] };
    }

    const response = {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(results),
    };

    if (callback) {
      response.headers["Content-Type"] = "application/javascript";
      response.body = ${callback}();
    }

    return response;
  } catch (error) {
    console.error('Reconcile error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({}),
    };
  }
};


--- File: netlify\functions\stream-chunk.js ---
Words: 212
const fs = require('fs').promises;
const path = require('path');
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { input } = JSON.parse(event.body || '{}');
    if (!input) {
      return {
        statusCode: 400,
        headers: { "Access-Control-Allow-Origin": "*" },
        body: JSON.stringify({ error: 'Input required' }),
      };
    }

    const chunks = [];
    for (let i = 0; i < input.length; i += 3) {
      chunks.push(input.slice(i, i + 3));
    }

    const dataDir = path.join(__dirname, '../../data');
    const files = await fs.readdir(dataDir);
    const matches = [];

    for (const file of files) {
      if (file.endsWith('.txt') || file.endsWith('.json')) {
        const content = await fs.readFile(path.join(dataDir, file), 'utf8');
        let fileData = content;
        if (file.endsWith('.json')) {
          fileData = JSON.stringify(JSON.parse(content));
        }

        for (const chunk of chunks) {
          if (fileData.toLowerCase().includes(chunk.toLowerCase())) {
            const prompt = Match chunk "" in file . Return context (20 chars before/after).;
            const llmResponse = await callGemini(prompt, {
              type: 'object',
              properties: { context: { type: 'string' } },
            });
            matches.push({
              chunk,
              file,
              context: llmResponse.context || fileData.slice(Math.max(0, fileData.indexOf(chunk) - 20), fileData.indexOf(chunk) + 23),
            });
          }
        }
      }
    }

    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ matches }),
    };
  } catch (error) {
    console.error('Stream chunk error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ matches: [] }),
    };
  }
};


--- File: netlify\functions\suggest-entity.js ---
Words: 124
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { prefix = '', type = '' } = event.queryStringParameters;
    const prompt = Suggest entities starting with "" for type "". Return as JSON with result array of {id, name, description}.;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        result: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
              description: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Suggest entity error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ result: [] }),
    };
  }
};


--- File: netlify\functions\suggest-property.js ---
Words: 118
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { prefix = '', type = '' } = event.queryStringParameters;
    const prompt = Suggest properties starting with "" for type "". Return as JSON with result array of {id, name}.;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        result: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Suggest property error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ result: [] }),
    };
  }
};


--- File: netlify\functions\suggest-type.js ---
Words: 112
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { prefix = '' } = event.queryStringParameters;
    const prompt = Suggest types starting with "". Return as JSON with result array of {id, name}.;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        result: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Suggest type error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ result: [] }),
    };
  }
};


--- File: netlify\functions\utils.js ---
Words: 139
const fetch = require('node-fetch');

async function callGemini(prompt, schema) {
  const apiKey = process.env.GEMINI_API_KEY;
  const response = await fetch(https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      contents: [{ role: 'user', parts: [{ text: prompt }] }],
      generationConfig: { responseMimeType: 'application/json', responseSchema: schema },
    }),
  });

  if (!response.ok) {
    throw new Error(API error: );
  }

  const result = await response.json();
  return JSON.parse(result.candidates[0].content.parts[0].text);
}

function getReconcileSchema() {
  return {
    type: 'object',
    properties: {
      result: {
        type: 'array',
        items: {
          type: 'object',
          properties: {
            id: { type: 'string' },
            name: { type: 'string' },
            score: { type: 'number' },
            match: { type: 'boolean' },
            type: {
              type: 'array',
              items: { type: 'object', properties: { id: { type: 'string' }, name: { type: 'string' } } },
            },
          },
        },
      },
    },
  };
}

module.exports = { callGemini, getReconcileSchema };


--- File: src\api.js ---
Words: 103
const express = require('express');
const metadataRouter = require('./routes/metadata');
const reconcileRouter = require('./routes/reconcile');
const suggestEntityRouter = require('./routes/suggest-entity');
// ...other routers
const previewRouter = require('./routes/preview');
const extendProposeRouter = require('./routes/extend-propose');
const extendRouter = require('./routes/extend');
const streamChunkRouter = require('./routes/stream-chunk');

const app = express();
app.use(express.json());

// Enable CORS
app.use((req, res, next) => {
  res.set('Access-Control-Allow-Origin', '*');
  next();
});

// Mount routes
app.use('/metadata', metadataRouter);
app.use('/reconcile', reconcileRouter);
app.use('/suggest/entity', suggestEntityRouter);
app.use('/suggest/type', require('./routes/suggest-type'));
app.use('/suggest/property', require('./routes/suggest-property'));
app.use('/preview', previewRouter);
app.use('/extend/propose', extendProposeRouter);
app.use('/extend', extendRouter);
app.use('/stream-chunk', streamChunkRouter);

// Error middleware
app.use((err, req, res, next) => {
  console.error(err);
  res.status(err.status || 500).json({
    status: err.status || 500,
    error: err.name,
    message: err.message,
    timestamp: new Date().toISOString(),
  });
});

module.exports = app;


--- File: src\swagger.js ---
Words: 88
const swaggerJsdoc = require('swagger-jsdoc');
const swaggerUi = require('swagger-ui-express');

const baseUrl = process.env.BASE_URL || 'http://localhost:8888';

const options = {
  definition: {
    openapi: '3.0.3',
    info: {
      title: 'Universal Reconciliation Service API',
      version: '1.0.0',
      description: 'API for reconciliation service using Express and Gemini API',
      contact: {
        name: 'Google',
        email: 'support@example.com',
      },
      license: {
        name: 'MIT',
        url: 'https://opensource.org/licenses/MIT',
      },
    },
    servers: [
      {
        url: baseUrl,
        description: 'Base URL of the API',
      },
    ],
  },
  apis: ['./netlify/functions/routes/*.js'],
};

const swaggerSpec = swaggerJsdoc(options);

function setupSwagger(app) {
  app.use('/api-docs', swaggerUi.serve, swaggerUi.setup(swaggerSpec));
}

module.exports = setupSwagger;


--- File: src\utils.js ---
Words: 612
const { GoogleGenerativeAI } = require('@google/generative-ai');
const { v4: uuidv4 } = require('uuid');
const path = require('path');
const fs = require('fs');
require('dotenv').config();

const API_KEY = proceupdatess.env.GEMINI_API_KEY;
if (!API_KEY) {
  console.error("GEMINI_API_KEY is not set. Please set the environment variable.");
  process.exit(1);
}
const genAI = new GoogleGenerativeAI(API_KEY);

// Helper function to get the Gemini model response
async function getModelResponse(prompt, isJson, useSearch) {
  try {
    const generationConfig = isJson ? { responseMimeType: "application/json" } : {};
    const tools = useSearch ? [{ google_search: {} }] : undefined;

    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash-preview-05-20", generationConfig, tools });

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    return { text };
  } catch (error) {
    console.error('Gemini API error:', error);
    throw new Error('Failed to get response from Gemini API.');
  }
}

// Helper function to get service metadata
function getServiceMetadata() {
  return {
    name: "Universal Reconciliation Service API",
    identifierSpace: "[http://www.freebase.com/ns/freebase](http://www.freebase.com/ns/freebase)",
    schemaSpace: "[http://www.freebase.com/ns/type.type](http://www.freebase.com/ns/type.type)",
    view: {
      url: "{{id}}"
    },
    defaultTypes: [{
      id: "/common/topic",
      name: "Topic"
    }],
    reconcile: {
      path: "/reconcile",
      serviceUrl: "/.netlify/functions/api"
    },
    suggest: {
      entity: {
        path: "/suggest/entity",
        serviceUrl: "/.netlify/functions/api"
      },
      type: {
        path: "/suggest/type",
        serviceUrl: "/.netlify/functions/api"
      },
      property: {
        path: "/suggest/property",
        serviceUrl: "/.netlify/functions/api"
      }
    },
    preview: {
      path: "/preview",
      serviceUrl: "/.netlify/functions/api"
    },
    extend: {
      propose_properties: {
        path: "/extend/propose",
        serviceUrl: "/.netlify/functions/api"
      },
      serviceUrl: "/.netlify/functions/api"
    }
  };
}

// Helper function to handle reconciliation matching
async function getMatchingResults(queries) {
  const results = {};
  for (const qid in queries) {
    const query = queries[qid];
    const userPrompt = `Reconcile the entity "${query.query}" against entities of type "${query.type}". Provide a list of 5 possible matches in JSON format, each with a 'name', 'id', 'score' (0-100), and 'type' property. The 'score' should reflect the confidence of the match.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const matches = JSON.parse(modelResponse.text);

    results[qid] = {
      result: matches.map(match => ({
        id: match.id || uuidv4(),
        name: match.name,
        score: match.score / 100,
        match: match.score > 70 ? true : false,
        type: [{
          id: match.type,
          name: match.type
        }]
      }))
    };
  }
  return results;
}

// Helper function to handle suggestions
async function getSuggestions(type, prefix) {
  let userPrompt;
  switch (type) {
    case 'entity':
      userPrompt = `Suggest 5 entities related to "${prefix}" in JSON format. Each entity should have a 'name' and 'id'.`;
      break;
    case 'type':
      userPrompt = `Suggest 5 data types related to "${prefix}" in JSON format. Each type should have a 'name' and 'id'.`;
      break;
    case 'property':
      userPrompt = `Suggest 5 properties that start with "${prefix}" in JSON format. Each property should have a 'name' and 'id'.`;
      break;
    default:
      throw new Error(`Invalid suggestion type: ${type}`);
  }

  const modelResponse = await getModelResponse(userPrompt, true, false);
  const suggestions = JSON.parse(modelResponse.text);

  return {
    result: suggestions.map(s => ({
      id: s.id || uuidv4(),
      name: s.name,
      description: s.description || ""
    }))
  };
}

// Helper function to get preview HTML
async function getPreviewHTML(id) {
  const userPrompt = `Generate a short HTML description for an entity with the ID "${id}". Make sure the HTML is well-formed.`;
  const modelResponse = await getModelResponse(userPrompt, true, false);
  return modelResponse.text;
}

// Helper function to get extended properties
async function getExtendedProperties(ids, properties) {
  const data = {};
  for (const id of ids) {
    const userPrompt = `For the entity with ID "${id}", retrieve the values for the following properties: ${properties.map(p => p.id).join(', ')}. Provide the result in a JSON object where keys are the property IDs and values are the corresponding values.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const values = JSON.parse(modelResponse.text);
    data[id] = values;
  }
  return {
    meta: properties.map(p => ({ id: p.id, name: p.name })),
    rows: ids.map(id => ({ id: id, values: properties.map(p => data[id][p.id] ? [{ str: data[id][p.id] }] : []) }))
  };
}


module.exports = {
  getServiceMetadata,
  getModelResponse,
  getMatchingResults,
  getSuggestions,
  getPreviewHTML,
  getExtendedProperties,
};



--- File: src\routes\extend-propose.js ---
Words: 149
/**
 * @swagger
 * /extend-propose:
 *   get:
 *     summary: Example GET endpoint for extend-propose
 *     description: Detailed description for the extend-propose endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const { v4: uuidv4 } = require('uuid');

// Extend Propose Route
// This endpoint proposes properties for data extension.
router.post('/', async (req, res) => {
  try {
    const type = req.body.type;
    const userPrompt = `Propose 5 properties to extend data for the entity type "${type}". Provide the suggestions in JSON format. Each property should have an 'id' and 'name'.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const properties = JSON.parse(modelResponse.text);

    res.status(200).json({
      properties: properties.map(p => ({
        id: p.id || uuidv4(),
        name: p.name
      }))
    });
  } catch (error) {
    console.error('Extend propose error:', error);
    res.status(500).json({ error: 'Failed to propose properties.' });
  }
});

module.exports = router;


--- File: src\routes\extend.js ---
Words: 207
/**
 * @swagger
 * /extend:
 *   get:
 *     summary: Example GET endpoint for extend
 *     description: Detailed description for the extend endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');

// Extend Route
// This endpoint extends data by adding properties to entities.
router.post('/', async (req, res) => {
  try {
    const ids = req.body.ids;
    const properties = req.body.properties;

    if (!ids || !properties || !Array.isArray(ids) || !Array.isArray(properties)) {
      return res.status(400).json({ error: 'Missing or invalid ids or properties.' });
    }

    const data = {};
    for (const id of ids) {
      const userPrompt = `For the entity with ID "${id}", retrieve the values for the following properties: ${properties.map(p => p.id).join(', ')}. Provide the result in a JSON object where keys are the property IDs and values are the corresponding values.`;
      const modelResponse = await getModelResponse(userPrompt, true, false);

      const values = JSON.parse(modelResponse.text);
      data[id] = values;
    }

    res.status(200).json({
      meta: properties.map(p => ({ id: p.id, name: p.name })),
      rows: ids.map(id => ({ id: id, values: properties.map(p => data[id][p.id] ? [{ str: data[id][p.id] }] : []) }))
    });
  } catch (error) {
    console.error('Extend error:', error);
    res.status(500).json({ error: 'Failed to extend data.' });
  }
});

module.exports = router;


--- File: src\routes\metadata.js ---
Words: 137
/**
 * @swagger
 * /metadata:
 *   get:
 *     summary: Example GET endpoint for metadata
 *     description: Detailed description for the metadata endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
// src/routes/metadata.js
const express = require('express');
const router = express.Router();

router.get('/', (req, res) => {
  const baseUrl = `${req.protocol}://${req.get('host')}`;
  res.json({
    name: 'Universal Reconciliation Service',
    identifierSpace: 'http://example.com/identifiers',
    schemaSpace: 'http://example.com/schemas',
    defaultTypes: [{ id: '/general', name: 'General Entity' }],
    view: { url: 'http://example.com/view/{{id}}' },
    preview: {
      url: `${baseUrl}/preview?id={{id}}`,
      width: 400,
      height: 200,
    },
    suggest: {
      entity: { service_url: baseUrl, service_path: '/suggest/entity' },
      type: { service_url: baseUrl, service_path: '/suggest/type' },
      property: { service_url: baseUrl, service_path: '/suggest/property' },
    },
    extend: {
      propose_properties: { service_url: baseUrl, service_path: '/extend/propose' },
      property_settings: [
        {
          name: 'maxItems',
          label: 'Maximum number of values',
          type: 'number',
          default: 1,
        },
      ],
    },
  });
});

module.exports = router;


--- File: src\routes\preview.js ---
Words: 128
/**
 * @swagger
 * /preview:
 *   get:
 *     summary: Example GET endpoint for preview
 *     description: Detailed description for the preview endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');

// Preview Route
// This endpoint generates a preview of an entity.
router.get('/', async (req, res) => {
  try {
    const id = req.query.id;
    if (!id) {
      return res.status(400).send('Entity ID is required.');
    }

    const userPrompt = `Generate a short HTML description for an entity with the ID "${id}". Make sure the HTML is well-formed.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const htmlContent = modelResponse.text;

    res.status(200).send(htmlContent);
  } catch (error) {
    console.error('Preview error:', error);
    res.status(500).send('Failed to generate preview.');
  }
});

module.exports = router;


--- File: src\routes\stream-chunk.js ---
Words: 203
/**
 * @swagger
 * /stream-chunk:
 *   get:
 *     summary: Example GET endpoint for stream-chunk
 *     description: Detailed description for the stream-chunk endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const path = require('path');
const fs = require('fs');

// Stream Chunk Route
// This endpoint handles real-time stream chunk matching.
router.post('/', async (req, res) => {
  try {
    const { input, fileName } = req.body;
    if (!input || !fileName) {
      return res.status(400).json({ error: 'Input text and file name are required.' });
    }

    const filePath = path.join(__dirname, '..', '..', 'data', fileName);
    if (!fs.existsSync(filePath)) {
      return res.status(404).json({ error: 'File not found.' });
    }

    const fileContent = fs.readFileSync(filePath, 'utf-8');
    const userPrompt = `Given the input chunk "${input}" and the following data:\n\n---\n${fileContent}\n---\n\nDetermine the best match from the data for the input chunk. Provide a JSON object with 'match' and 'confidence' (0-100) properties. If no match is found, set 'match' to null.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const result = JSON.parse(modelResponse.text);

    res.status(200).json({
      match: result.match,
      confidence: result.confidence / 100
    });
  } catch (error) {
    console.error('Stream chunk error:', error);
    res.status(500).json({ error: 'Failed to process stream chunk.' });
  }
});

module.exports = router;



--- File: src\routes\suggest-property.js ---
Words: 195
/**
 * @swagger
 * /suggest-property:
 *   get:
 *     summary: Example GET endpoint for suggest-property
 *     description: Detailed description for the suggest-property endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const { v4: uuidv4 } = require('uuid');

// Suggest Property Route
// This endpoint suggests properties based on a query.
router.get('/', async (req, res) => {
  try {
    const query = req.query.prefix;
    const type = req.query.type;
    if (!query) {
      return res.status(400).json({ error: 'Query prefix is required.' });
    }

    let userPrompt;
    if (type) {
      userPrompt = `Suggest 5 properties for a data type named "${type}" that start with "${query}". Provide the suggestions in JSON format, each with a 'name' and 'id'.`;
    } else {
      userPrompt = `Suggest 5 properties that start with "${query}" in JSON format. Each property should have a 'name' and 'id'.`;
    }
    
    const modelResponse = await getModelResponse(userPrompt, true, false);
    const suggestions = JSON.parse(modelResponse.text);

    res.status(200).json({
      result: suggestions.map(s => ({
        id: s.id || uuidv4(),
        name: s.name
      }))
    });
  } catch (error) {
    console.error('Suggest property error:', error);
    res.status(500).json({ error: 'Failed to get property suggestions.' });
  }
});

module.exports = router;


--- File: tests\accuracy.test.js ---
Words: 132
const request = require('supertest');

// Set the base URL from an environment variable for flexibility.
const baseUrl = process.env.BASE_URL || 'http://localhost:8888/.netlify/functions/api';

describe('Accuracy Tests', () => {
  // Tests the accuracy of the reconciliation endpoint.
  test('Reconcile accuracy for a known entity', async () => {
    const response = await request(baseUrl)
      .post('/reconcile')
      .send({ queries: { q0: { query: 'Paris', type: '/location' } } });

    // The first result should contain "Paris" and have a high confidence score.
    const result = response.body.q0.result[0];
    expect(result.name).toContain('Paris');
    expect(result.score).toBeGreaterThan(0.8);
  });

  // Tests the accuracy of the stream-chunk endpoint.
  test('Stream chunk accuracy for a valid input', async () => {
    const response = await request(baseUrl)
      .post('/stream-chunk')
      .send({ input: 'Apple Inc.', fileName: 'sample.json' });

    // The API should return a high-confidence match.
    const result = response.body;
    expect(result.match).toBe('Apple Inc.');
    expect(result.confidence).toBeGreaterThan(0.8);
  });
});


--- File: tests\performance.test.js ---
Words: 138
const request = require('supertest');

// Set the base URL from an environment variable for flexibility.
const baseUrl = process.env.BASE_URL || 'http://localhost:8888/.netlify/functions/api';

describe('Performance Tests', () => {
  // Tests the latency of the reconciliation endpoint.
  test('Reconcile endpoint latency', async () => {
    const start = Date.now();
    await request(baseUrl)
      .post('/reconcile')
      .send({ queries: { q0: { query: 'Paris', type: '/location', limit: 3 } } });
      
    const latency = Date.now() - start;
    console.log(`Reconcile latency: ${latency}ms`);
    // Ensure the response time is less than 10 seconds.
    expect(latency).toBeLessThan(10000);
  });

  // Tests the latency of the stream chunk endpoint.
  test('Stream chunk endpoint latency', async () => {
    const start = Date.now();
    await request(baseUrl)
      .post('/stream-chunk')
      .send({ input: 'Apple Inc.', fileName: 'sample.json' });

    const latency = Date.now() - start;
    console.log(`Stream chunk latency: ${latency}ms`);
    // Ensure the response time is less than 10 seconds.
    expect(latency).toBeLessThan(10000);
  });
});


--- File: tests\stream.test.js ---
Words: 137
const request = require('supertest');

// Set the base URL from an environment variable for flexibility.
const baseUrl = process.env.BASE_URL || 'http://localhost:8888/.netlify/functions/api';

describe('Stream Chunk Tests', () => {
  // Tests that the endpoint returns the correct structure for a valid chunk.
  test('Returns correct match and confidence for a valid chunk', async () => {
    const response = await request(baseUrl)
      .post('/stream-chunk')
      .send({ input: 'Apple Inc.', fileName: 'sample.json' });
    
    // The new API returns a single `match` and `confidence` score.
    expect(response.status).toBe(200);
    expect(response.body).toHaveProperty('match');
    expect(response.body).toHaveProperty('confidence');
    expect(typeof response.body.match).toBe('string');
    expect(typeof response.body.confidence).toBe('number');
  });

  // Tests that the endpoint handles empty input gracefully.
  test('Handles empty input and missing filename', async () => {
    const response = await request(baseUrl)
      .post('/stream-chunk')
      .send({ input: '', fileName: '' });
      
    // The API should return a 400 Bad Request error.
    expect(response.status).toBe(400);
    expect(response.body.error).toBe('Input text and file name are required.');
  });
});


--- File: public\index.html ---
Words: 24
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Reconciliation Service</title>
</head>
<body>
  <h1>Reconciliation Service API</h1>
  <p>This site hosts backend functions only.</p>
</body>
</html>


--- File: project_analysis_script.ps1 ---
Words: 676
# Get the current directory name to use as the project name
$projectName = Get-Item -Path . | Select-Object -ExpandProperty Name

# Define the output file path based on the project name
$outputFile = ".\$($projectName)_ProjectSummary.txt"

# Get the full path of the current directory to use as a root for relative paths
$currentDirectory = Get-Location

# Define common source code file extensions
$sourceExtensions = @("*.cs", "*.py", "*.js", "*.java", "*.html", "*.css", "*.cpp", "*.h", "*.ts", "*.jsx", "*.tsx", "*.php", "*.rb", "*.go", "*.sh", "*.ps1", "*.bat")

# Define common dataset/data-related file extensions
$dataExtensions = @("*.json", "*.xml", "*.csv", "*.txt", "*.md", "*.yml", "*.yaml", "*.sql")

# Define files and directories to ignore
$excludePatterns = @("node_modules", ".env", ".git", ".gitignore", "package-lock.json", "yarn.lock", "*.log", "dist", "build", "bin", "obj", "*.lock", "*.zip", "*.rar", "*.exe", "*.dll")

# Initialize variables to track word counts
$totalSourceCodeWords = 0
$totalDataWords = 0

# --- Function to get a timestamp ---
function Get-Timestamp {
    return Get-Date -Format "yyyy-MM-dd HH:mm:ss"
}

# --- Function to write professional metadata ---
function Write-Metadata {
    param (
        [string]$filePath,
        [string]$projectName,
        [int]$sourceWords,
        [int]$dataWords
    )
    Add-Content -Path $filePath -Value "===== Project Summary ====="
    Add-Content -Path $filePath -Value "Project Name: $projectName"
    Add-Content -Path $filePath -Value "Generation Date: $(Get-Timestamp)"
    Add-Content -Path $filePath -Value "Generated By: PowerShell Script"
    Add-Content -Path $filePath -Value "Total Source Code Words: $sourceWords"
    Add-Content -Path $filePath -Value "Total Dataset/Text Words: $dataWords"
    Add-Content -Path $filePath -Value "Description: A comprehensive summary of the project's structure, source code, and data files, designed for secure LLM context submission."
    Add-Content -Path $filePath -Value "==========================="
    Add-Content -Path $filePath -Value "`n"
}

# Clear the output file if it already exists
if (Test-Path $outputFile) {
    Remove-Item $outputFile -Force
}

# Write a temporary metadata header to be updated later
Add-Content -Path $outputFile -Value "===== Project Summary =====
Project Name: universal-reconciliation-service
Generation Date: 2025-09-05 01:24:19
Generated By: PowerShell Script
Total Source Code Words: 6194
Total Dataset/Text Words: 16376
Description: A comprehensive summary of the project's structure, source code, and data files, designed for secure LLM context submission.
===========================
"

# Write the directory structure to the output file, excluding specified patterns
Add-Content -Path $outputFile -Value "===== Directory Structure ====="
$allFiles = Get-ChildItem -Recurse -File | Where-Object {
    $path = $_.FullName
    $shouldInclude = $true
    foreach ($pattern in $excludePatterns) {
        if ($path -like "*$pattern*") {
            $shouldInclude = $false
            break
        }
    }
    $shouldInclude
}

$directoryStructure = $allFiles | ForEach-Object { 
    $_.FullName.Replace($currentDirectory.Path + "\", "") 
} | Out-String
Add-Content -Path $outputFile -Value $directoryStructure

# Add a separator for source code files
Add-Content -Path $outputFile -Value "`n===== Source Code Files ====="

# Loop through source code files
foreach ($ext in $sourceExtensions) {
    $allFiles | Where-Object { $_.Name -like $ext } | ForEach-Object {
        $filePath = $_.FullName
        $relativePath = $filePath.Replace($currentDirectory.Path + "\", "")
        $fileContent = Get-Content -Path $filePath -Raw
        
        # Count words and add to total
        $wordCount = ($fileContent -split '\s+').Count
        $totalSourceCodeWords += $wordCount
        
        Add-Content -Path $outputFile -Value "`n--- File: $relativePath ---"
        Add-Content -Path $outputFile -Value "Words: $wordCount"
        Add-Content -Path $outputFile -Value $fileContent
    }
}

# Add a separator for dataset files
Add-Content -Path $outputFile -Value "`n===== Datasets and Text Files ====="

# Loop through dataset files
foreach ($ext in $dataExtensions) {
    $allFiles | Where-Object { $_.Name -like $ext } | ForEach-Object {
        $filePath = $_.FullName
        $relativePath = $filePath.Replace($currentDirectory.Path + "\", "")
        $fileContent = Get-Content -Path $filePath -Raw
        $wordCount = ($fileContent -split '\s+').Count
        $totalDataWords += $wordCount

        Add-Content -Path $outputFile -Value "`n--- File: $relativePath ---"
        Add-Content -Path $outputFile -Value "Words: $wordCount"

        # Special handling for CSV files
        if ($_.Extension -eq ".csv") {
            # Read first few lines of CSV for context
            $csvContent = Get-Content -Path $filePath -Raw | Select-Object -First 6
            Add-Content -Path $outputFile -Value "Content (first 5 rows):"
            Add-Content -Path $outputFile -Value ($csvContent | Out-String)
            Add-Content -Path $outputFile -Value "... (full content omitted for brevity)"
        } else {
            # For other data types, include full content
            Add-Content -Path $outputFile -Value $fileContent
        }
    }
}

# --- Update the metadata with the final word count ---
$finalContent = Get-Content -Path $outputFile -Raw
$metadataHeader = @"
===== Project Summary =====
Project Name: $projectName
Generation Date: $(Get-Timestamp)
Generated By: PowerShell Script
Total Source Code Words: $totalSourceCodeWords
Total Dataset/Text Words: $totalDataWords
Description: A comprehensive summary of the project's structure, source code, and data files, designed for secure LLM context submission.
===========================

"@
$finalContent = $finalContent.Replace("===== Project Summary =====
Project Name: universal-reconciliation-service
Generation Date: 2025-09-05 01:24:19
Generated By: PowerShell Script
Total Source Code Words: 6194
Total Dataset/Text Words: 16376
Description: A comprehensive summary of the project's structure, source code, and data files, designed for secure LLM context submission.
===========================
", $metadataHeader)
$finalContent | Set-Content -Path $outputFile

Write-Host "Project structure and source code have been saved to $outputFile"

===== Datasets and Text Files =====

--- File: package.json ---
Words: 91
{
  "name": "universal-reconciliation-service",
  "version": "1.0.0",
  "description": "A Universal Reconciliation Service API using Express and Gemini API, deployable to Netlify.",
  "main": "netlify/functions/api.js",
  "type": "commonjs",
  "scripts": {
    "start": "node src/api.js",
    "dev": "netlify dev",
    "deploy": "netlify deploy --prod",
    "test": "jest",
    "analyze": "python analysis/performance_analysis.py",
    "build": "echo 'No build needed for serverless functions'"
  },
  "keywords": [
    "reconciliation",
    "api",
    "openrefine",
    "gemini",
    "netlify",
    "serverless",
    "express"
  ],
  "author": "Google",
  "license": "MIT",
  "dependencies": {
    "@google/generative-ai": "^0.1.3",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "express": "^4.18.2",
    "serverless-http": "^3.2.0",
    "uuid": "^9.0.1",
    "winston": "^3.8.2"
  },
  "devDependencies": {
    "jest": "^29.7.0",
    "netlify-cli": "^23.5.0",
    "supertest": "^6.3.3"
  }
}


--- File: .netlify\state.json ---
Words: 35
{
	"geolocation": {
		"data": {
			"city": "Edinburgh",
			"country": {
				"code": "GB",
				"name": "United Kingdom"
			},
			"subdivision": {
				"code": "SCT",
				"name": "Scotland"
			},
			"timezone": "Europe/London",
			"latitude": 55.9632,
			"longitude": -3.2546,
			"postalCode": "EH4"
		},
		"timestamp": 1756827433493
	}
}

--- File: data\sample.json ---
Words: 15
[
  { "city": "Paris", "country": "France" },
  { "city": "London", "country": "UK" }
]


--- File: dataset\development\dev-famous-scientists.json ---
Words: 93
[
  { "name": "Albert Einstein", "query": "Einstein", "type": "person" },
  { "name": "Marie Curie", "query": "Curie", "type": "person" },
  { "name": "Isaac Newton", "query": "Newton", "type": "person" },
  { "name": "Galileo Galilei", "query": "Galileo", "type": "person" },
  { "name": "Nikola Tesla", "query": "Tesla", "type": "person" },
  { "name": "Charles Darwin", "query": "Darwin", "type": "person" },
  { "name": "Stephen Hawking", "query": "Hawking", "type": "person" },
  { "name": "Rosalind Franklin", "query": "Franklin", "type": "person" },
  { "name": "Alan Turing", "query": "Turing", "type": "person" },
  { "name": "Linus Pauling", "query": "Pauling", "type": "person" }
]


--- File: dataset\development\dev-landmarks.json ---
Words: 131
[
  { "name": "Eiffel Tower", "query": "Eiffel Tower", "type": "landmark" },
  { "name": "Statue of Liberty", "query": "Statue of Liberty", "type": "landmark" },
  { "name": "Great Wall of China", "query": "Great Wall of China", "type": "landmark" },
  { "name": "Colosseum", "query": "Colosseum", "type": "landmark" },
  { "name": "Taj Mahal", "query": "Taj Mahal", "type": "landmark" },
  { "name": "Pyramids of Giza", "query": "Pyramids of Giza", "type": "landmark" },
  { "name": "Machu Picchu", "query": "Machu Picchu", "type": "landmark" },
  { "name": "Christ the Redeemer", "query": "Christ the Redeemer", "type": "landmark" },
  { "name": "Stonehenge", "query": "Stonehenge", "type": "landmark" },
  { "name": "Burj Khalifa", "query": "Burj Khalifa", "type": "landmark" },
  { "name": "Sydney Opera House", "query": "Sydney Opera House", "type": "landmark" },
  { "name": "The Alamo", "query": "The Alamo", "type": "landmark" }
]


--- File: dataset\development\dev-major-cities.json ---
Words: 90
[
  { "name": "New York City", "query": "New York", "type": "city" },
  { "name": "Tokyo", "query": "Tokyo", "type": "city" },
  { "name": "London", "query": "London", "type": "city" },
  { "name": "Paris", "query": "Paris", "type": "city" },
  { "name": "Sydney", "query": "Sydney", "type": "city" },
  { "name": "Beijing", "query": "Beijing", "type": "city" },
  { "name": "Rio de Janeiro", "query": "Rio de Janeiro", "type": "city" },
  { "name": "Mumbai", "query": "Mumbai", "type": "city" },
  { "name": "Moscow", "query": "Moscow", "type": "city" },
  { "name": "Cairo", "query": "Cairo", "type": "city" }
]


--- File: dataset\development\dev-popular-movies.json ---
Words: 109
[
  { "name": "Inception", "query": "Inception", "type": "movie" },
  { "name": "The Godfather", "query": "The Godfather", "type": "movie" },
  { "name": "Pulp Fiction", "query": "Pulp Fiction", "type": "movie" },
  { "name": "The Dark Knight", "query": "The Dark Knight", "type": "movie" },
  { "name": "Forrest Gump", "query": "Forrest Gump", "type": "movie" },
  { "name": "The Shawshank Redemption", "query": "The Shawshank Redemption", "type": "movie" },
  { "name": "Fight Club", "query": "Fight Club", "type": "movie" },
  { "name": "The Matrix", "query": "The Matrix", "type": "movie" },
  { "name": "Goodfellas", "query": "Goodfellas", "type": "movie" },
  { "name": "The Silence of the Lambs", "query": "The Silence of the Lambs", "type": "movie" }
]


--- File: dataset\development\dev-tech-companies.json ---
Words: 87
[
  { "name": "Alphabet Inc.", "query": "Google" },
  { "name": "Apple Inc.", "query": "Apple" },
  { "name": "Microsoft Corp.", "query": "Microsoft" },
  { "name": "Amazon.com Inc.", "query": "Amazon" },
  { "name": "Meta Platforms, Inc.", "query": "Facebook", "type": "company" },
  { "name": "Tesla, Inc.", "query": "Tesla" },
  { "name": "Nvidia Corporation", "query": "Nvidia" },
  { "name": "Alibaba Group Holding Ltd.", "query": "Alibaba" },
  { "name": "Samsung Electronics Co., Ltd.", "query": "Samsung" },
  { "name": "Intel Corporation", "query": "Intel" },
  { "name": "Netflix, Inc.", "query": "Netflix" }
]


--- File: dataset\production\prod-ambiguous-entities.json ---
Words: 89
[
  { "name": "The Flash (DC Comics)", "query": "Flash" },
  { "name": "Taylor Swift", "query": "Taylor Swift" },
  { "name": "Tyler Swift", "query": "Tyler Swift" },
  { "name": "N.W.A.", "query": "NWA" },
  { "name": "Apple (Fruit)", "query": "Apple" },
  { "name": "The Eagles (band)", "query": "Eagles" },
  { "name": "Amazon River", "query": "Amazon" },
  { "name": "The Lord of the Rings: The Fellowship of the Ring", "query": "Fellowship of the Ring" },
  { "name": "Chicago Bulls", "query": "Bulls" },
  { "name": "Python (Programming Language)", "query": "Python" }
]


--- File: dataset\production\prod-financial-instruments.json ---
Words: 68
[
  { "name": "S&P 500 Index", "query": "Standard & Poor's 500" },
  { "name": "Dow Jones Industrial Average", "query": "Dow Jones" },
  { "name": "Bitcoin", "query": "Bitcoin", "type": "cryptocurrency" },
  { "name": "Ethereum", "query": "ETH", "type": "cryptocurrency" },
  { "name": "Treasury Bill", "query": "T-bill", "type": "security" },
  { "name": "Exchange-Traded Fund", "query": "ETF", "type": "investment" },
  { "name": "Mutual Fund", "query": "Mutual Fund", "type": "investment" }
]


--- File: dataset\production\prod-historical-events.json ---
Words: 102
[
  { "name": "World War II", "query": "WWII" },
  { "name": "The French Revolution", "query": "French Revolution" },
  { "name": "The Fall of the Berlin Wall", "query": "Berlin Wall Fall" },
  { "name": "The Renaissance", "query": "Renaissance" },
  { "name": "The Age of Enlightenment", "query": "Enlightenment" },
  { "name": "The American Civil War", "query": "Civil War" },
  { "name": "The invention of the printing press", "query": "Gutenberg printing press" },
  { "name": "The Space Race", "query": "Space Race" },
  { "name": "The first moon landing", "query": "moon landing" },
  { "name": "The Boston Tea Party", "query": "Boston Tea Party" }
]


--- File: dataset\production\prod-legal-precedents.json ---
Words: 60
[
  { "name": "Miranda v. Arizona", "query": "Miranda rights" },
  { "name": "Roe v. Wade", "query": "Roe v. Wade" },
  { "name": "Brown v. Board of Education", "query": "Brown vs Board", "type": "legal_case" },
  { "name": "Marbury v. Madison", "query": "judicial review case", "type": "legal_case" },
  { "name": "Plessy v. Ferguson", "query": "separate but equal", "type": "legal_case" }
]


--- File: dataset\production\prod-medical-diagnoses.json ---
Words: 75
[
  { "name": "Myocardial Infarction", "query": "heart attack" },
  { "name": "Hypertension", "query": "high blood pressure" },
  { "name": "Diabetes Mellitus Type 2", "query": "Type 2 diabetes" },
  { "name": "Alzheimer's Disease", "query": "Alzheimer's", "type": "neurological_condition" },
  { "name": "Schizophrenia", "query": "Schizophrenia", "type": "mental_health" },
  { "name": "Hepatitis C", "query": "Hepatitis C", "type": "disease" },
  { "name": "Tuberculosis", "query": "TB", "type": "infectious_disease" },
  { "name": "Osteoporosis", "query": "bone density loss", "type": "condition" }
]


--- File: dataset\production\prod-musical-artists.json ---
Words: 71
[
  { "name": "Taylor Swift", "query": "Taylor Swift" },
  { "name": "The Beatles", "query": "Beatles" },
  { "name": "Beyonc", "query": "Beyonce" },
  { "name": "Elvis Presley", "query": "Elvis" },
  { "name": "Michael Jackson", "query": "Michael Jackson" },
  { "name": "Queen", "query": "Queen" },
  { "name": "Led Zeppelin", "query": "Led Zeppelin" },
  { "name": "Eminem", "query": "Eminem" },
  { "name": "Adele", "query": "Adele" },
  { "name": "Drake", "query": "Drake" }
]


--- File: dataset\production\prod-professional-titles.json ---
Words: 49
[
  { "name": "Certified Public Accountant", "query": "CPA" },
  { "name": "Chief Executive Officer", "query": "CEO" },
  { "name": "Doctor of Medicine", "query": "MD" },
  { "name": "Juris Doctor", "query": "JD" },
  { "name": "Project Management Professional", "query": "PMP" },
  { "name": "Registered Nurse", "query": "RN" }
]


--- File: dataset\production\prod-scientific-terms.json ---
Words: 102
[
  { "name": "Quantum Entanglement", "query": "Quantum Entanglement", "type": "physics" },
  { "name": "Myocardial Infarction", "query": "heart attack", "type": "medical_condition" },
  { "name": "Neural Network", "query": "backpropagation algorithm", "type": "AI" },
  { "name": "RNA Splicing", "query": "RNA splicing", "type": "biology" },
  { "name": "General Relativity", "query": "theory of relativity", "type": "physics" },
  { "name": "Photosynthesis", "query": "photosynthesis", "type": "biology" },
  { "name": "Black Hole", "query": "black hole", "type": "astronomy" },
  { "name": "Cybersecurity Taxonomy (NIST)", "query": "NIST CSF", "type": "cybersecurity" },
  { "name": "Vulnerability Management", "query": "Vulnerability management", "type": "cybersecurity" },
  { "name": "Data Encryption", "query": "Cryptography", "type": "cybersecurity" }
]


--- File: dataset\production\prod-sports-teams.json ---
Words: 88
[
  { "name": "New York Yankees", "query": "Yankees" },
  { "name": "Los Angeles Lakers", "query": "Lakers" },
  { "name": "Real Madrid C.F.", "query": "Real Madrid" },
  { "name": "FC Barcelona", "query": "Barcelona" },
  { "name": "Manchester United F.C.", "query": "Manchester United" },
  { "name": "Boston Red Sox", "query": "Red Sox" },
  { "name": "Chicago Bulls", "query": "Chicago Bulls" },
  { "name": "Green Bay Packers", "query": "Green Bay Packers" },
  { "name": "Golden State Warriors", "query": "Golden State Warriors" },
  { "name": "Pittsburgh Steelers", "query": "Steelers" }
]


--- File: dataset\special\special-100-entries.json ---
Words: 147
[
  {
    "name": "Neural Network",
    "query": "A variant of backpropagation algorithm",
    "type": "AI"
  },
  {
    "name": "The Godfather",
    "query": "The Godfather"
  },
  {
    "name": "Apple Inc.",
    "query": "A variant of Apple"
  },
  {
    "name": "Sarbanes-Oxley Act",
    "query": "SOX Act",
    "type": "legal"
  },
  {
    "name": "Quantum Entanglement",
    "query": "quantum entanglement",
    "type": "physics"
  },
  {
    "name": "Albert Einstein",
    "query": "A variant of Einstein"
  },
  {
    "name": "Taylor Swift",
    "query": "Taylor Swift"
  },
  {
    "name": "Myocardial Infarction",
    "query": "heart attack",
    "type": "medical_condition"
  },
  {
    "name": "Microsoft Corp.",
    "query": "Microsooft"
  },
  {
    "name": "The Lord of the Rings: The Fellowship of the Ring",
    "query": "Fellowship of the Ring"
  },
  {
    "name": "Gross Domestic Product",
    "query": "A variant of GDP",
    "type": "economics"
  },
  {
    "name": "N.W.A.",
    "query": "NWA"
  },
  {
    "name": "Apple Inc.",
    "query": "Aapple"
  },
  {
    "name": "The Godfather",
    "query": "The Godfather"
  },
  {
    "name": "London",
    "query": "Loondon"
  }
]


--- File: all_code_dump.txt ---
Words: 1850
==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\api.js ====

const express = require('express');
const metadataRouter = require('./routes/metadata');
const reconcileRouter = require('./routes/reconcile');
const suggestEntityRouter = require('./routes/suggest-entity');
// ...other routers
const previewRouter = require('./routes/preview');
const extendProposeRouter = require('./routes/extend-propose');
const extendRouter = require('./routes/extend');
const streamChunkRouter = require('./routes/stream-chunk');

const app = express();
app.use(express.json());

// Enable CORS
app.use((req, res, next) => {
  res.set('Access-Control-Allow-Origin', '*');
  next();
});

// Mount routes
app.use('/metadata', metadataRouter);
app.use('/reconcile', reconcileRouter);
app.use('/suggest/entity', suggestEntityRouter);
app.use('/suggest/type', require('./routes/suggest-type'));
app.use('/suggest/property', require('./routes/suggest-property'));
app.use('/preview', previewRouter);
app.use('/extend/propose', extendProposeRouter);
app.use('/extend', extendRouter);
app.use('/stream-chunk', streamChunkRouter);

// Error middleware
app.use((err, req, res, next) => {
  console.error(err);
  res.status(err.status || 500).json({
    status: err.status || 500,
    error: err.name,
    message: err.message,
    timestamp: new Date().toISOString(),
  });
});

module.exports = app;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\swagger.js ====

const swaggerJsdoc = require('swagger-jsdoc');
const swaggerUi = require('swagger-ui-express');

const baseUrl = process.env.BASE_URL || 'http://localhost:8888';

const options = {
  definition: {
    openapi: '3.0.3',
    info: {
      title: 'Universal Reconciliation Service API',
      version: '1.0.0',
      description: 'API for reconciliation service using Express and Gemini API',
      contact: {
        name: 'Google',
        email: 'support@example.com',
      },
      license: {
        name: 'MIT',
        url: 'https://opensource.org/licenses/MIT',
      },
    },
    servers: [
      {
        url: baseUrl,
        description: 'Base URL of the API',
      },
    ],
  },
  apis: ['./netlify/functions/routes/*.js'],
};

const swaggerSpec = swaggerJsdoc(options);

function setupSwagger(app) {
  app.use('/api-docs', swaggerUi.serve, swaggerUi.setup(swaggerSpec));
}

module.exports = setupSwagger;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\utils.js ====

const { GoogleGenerativeAI } = require('@google/generative-ai');
const { v4: uuidv4 } = require('uuid');
const path = require('path');
const fs = require('fs');
require('dotenv').config();

const API_KEY = proceupdatess.env.GEMINI_API_KEY;
if (!API_KEY) {
  console.error("GEMINI_API_KEY is not set. Please set the environment variable.");
  process.exit(1);
}
const genAI = new GoogleGenerativeAI(API_KEY);

// Helper function to get the Gemini model response
async function getModelResponse(prompt, isJson, useSearch) {
  try {
    const generationConfig = isJson ? { responseMimeType: "application/json" } : {};
    const tools = useSearch ? [{ google_search: {} }] : undefined;

    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash-preview-05-20", generationConfig, tools });

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    return { text };
  } catch (error) {
    console.error('Gemini API error:', error);
    throw new Error('Failed to get response from Gemini API.');
  }
}

// Helper function to get service metadata
function getServiceMetadata() {
  return {
    name: "Universal Reconciliation Service API",
    identifierSpace: "[http://www.freebase.com/ns/freebase](http://www.freebase.com/ns/freebase)",
    schemaSpace: "[http://www.freebase.com/ns/type.type](http://www.freebase.com/ns/type.type)",
    view: {
      url: "{{id}}"
    },
    defaultTypes: [{
      id: "/common/topic",
      name: "Topic"
    }],
    reconcile: {
      path: "/reconcile",
      serviceUrl: "/.netlify/functions/api"
    },
    suggest: {
      entity: {
        path: "/suggest/entity",
        serviceUrl: "/.netlify/functions/api"
      },
      type: {
        path: "/suggest/type",
        serviceUrl: "/.netlify/functions/api"
      },
      property: {
        path: "/suggest/property",
        serviceUrl: "/.netlify/functions/api"
      }
    },
    preview: {
      path: "/preview",
      serviceUrl: "/.netlify/functions/api"
    },
    extend: {
      propose_properties: {
        path: "/extend/propose",
        serviceUrl: "/.netlify/functions/api"
      },
      serviceUrl: "/.netlify/functions/api"
    }
  };
}

// Helper function to handle reconciliation matching
async function getMatchingResults(queries) {
  const results = {};
  for (const qid in queries) {
    const query = queries[qid];
    const userPrompt = `Reconcile the entity "${query.query}" against entities of type "${query.type}". Provide a list of 5 possible matches in JSON format, each with a 'name', 'id', 'score' (0-100), and 'type' property. The 'score' should reflect the confidence of the match.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const matches = JSON.parse(modelResponse.text);

    results[qid] = {
      result: matches.map(match => ({
        id: match.id || uuidv4(),
        name: match.name,
        score: match.score / 100,
        match: match.score > 70 ? true : false,
        type: [{
          id: match.type,
          name: match.type
        }]
      }))
    };
  }
  return results;
}

// Helper function to handle suggestions
async function getSuggestions(type, prefix) {
  let userPrompt;
  switch (type) {
    case 'entity':
      userPrompt = `Suggest 5 entities related to "${prefix}" in JSON format. Each entity should have a 'name' and 'id'.`;
      break;
    case 'type':
      userPrompt = `Suggest 5 data types related to "${prefix}" in JSON format. Each type should have a 'name' and 'id'.`;
      break;
    case 'property':
      userPrompt = `Suggest 5 properties that start with "${prefix}" in JSON format. Each property should have a 'name' and 'id'.`;
      break;
    default:
      throw new Error(`Invalid suggestion type: ${type}`);
  }

  const modelResponse = await getModelResponse(userPrompt, true, false);
  const suggestions = JSON.parse(modelResponse.text);

  return {
    result: suggestions.map(s => ({
      id: s.id || uuidv4(),
      name: s.name,
      description: s.description || ""
    }))
  };
}

// Helper function to get preview HTML
async function getPreviewHTML(id) {
  const userPrompt = `Generate a short HTML description for an entity with the ID "${id}". Make sure the HTML is well-formed.`;
  const modelResponse = await getModelResponse(userPrompt, true, false);
  return modelResponse.text;
}

// Helper function to get extended properties
async function getExtendedProperties(ids, properties) {
  const data = {};
  for (const id of ids) {
    const userPrompt = `For the entity with ID "${id}", retrieve the values for the following properties: ${properties.map(p => p.id).join(', ')}. Provide the result in a JSON object where keys are the property IDs and values are the corresponding values.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const values = JSON.parse(modelResponse.text);
    data[id] = values;
  }
  return {
    meta: properties.map(p => ({ id: p.id, name: p.name })),
    rows: ids.map(id => ({ id: id, values: properties.map(p => data[id][p.id] ? [{ str: data[id][p.id] }] : []) }))
  };
}


module.exports = {
  getServiceMetadata,
  getModelResponse,
  getMatchingResults,
  getSuggestions,
  getPreviewHTML,
  getExtendedProperties,
};




==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\extend-propose.js ====

/**
 * @swagger
 * /extend-propose:
 *   get:
 *     summary: Example GET endpoint for extend-propose
 *     description: Detailed description for the extend-propose endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const { v4: uuidv4 } = require('uuid');

// Extend Propose Route
// This endpoint proposes properties for data extension.
router.post('/', async (req, res) => {
  try {
    const type = req.body.type;
    const userPrompt = `Propose 5 properties to extend data for the entity type "${type}". Provide the suggestions in JSON format. Each property should have an 'id' and 'name'.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const properties = JSON.parse(modelResponse.text);

    res.status(200).json({
      properties: properties.map(p => ({
        id: p.id || uuidv4(),
        name: p.name
      }))
    });
  } catch (error) {
    console.error('Extend propose error:', error);
    res.status(500).json({ error: 'Failed to propose properties.' });
  }
});

module.exports = router;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\extend.js ====

/**
 * @swagger
 * /extend:
 *   get:
 *     summary: Example GET endpoint for extend
 *     description: Detailed description for the extend endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');

// Extend Route
// This endpoint extends data by adding properties to entities.
router.post('/', async (req, res) => {
  try {
    const ids = req.body.ids;
    const properties = req.body.properties;

    if (!ids || !properties || !Array.isArray(ids) || !Array.isArray(properties)) {
      return res.status(400).json({ error: 'Missing or invalid ids or properties.' });
    }

    const data = {};
    for (const id of ids) {
      const userPrompt = `For the entity with ID "${id}", retrieve the values for the following properties: ${properties.map(p => p.id).join(', ')}. Provide the result in a JSON object where keys are the property IDs and values are the corresponding values.`;
      const modelResponse = await getModelResponse(userPrompt, true, false);

      const values = JSON.parse(modelResponse.text);
      data[id] = values;
    }

    res.status(200).json({
      meta: properties.map(p => ({ id: p.id, name: p.name })),
      rows: ids.map(id => ({ id: id, values: properties.map(p => data[id][p.id] ? [{ str: data[id][p.id] }] : []) }))
    });
  } catch (error) {
    console.error('Extend error:', error);
    res.status(500).json({ error: 'Failed to extend data.' });
  }
});

module.exports = router;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\metadata.js ====

/**
 * @swagger
 * /metadata:
 *   get:
 *     summary: Example GET endpoint for metadata
 *     description: Detailed description for the metadata endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
// src/routes/metadata.js
const express = require('express');
const router = express.Router();

router.get('/', (req, res) => {
  const baseUrl = `${req.protocol}://${req.get('host')}`;
  res.json({
    name: 'Universal Reconciliation Service',
    identifierSpace: 'http://example.com/identifiers',
    schemaSpace: 'http://example.com/schemas',
    defaultTypes: [{ id: '/general', name: 'General Entity' }],
    view: { url: 'http://example.com/view/{{id}}' },
    preview: {
      url: `${baseUrl}/preview?id={{id}}`,
      width: 400,
      height: 200,
    },
    suggest: {
      entity: { service_url: baseUrl, service_path: '/suggest/entity' },
      type: { service_url: baseUrl, service_path: '/suggest/type' },
      property: { service_url: baseUrl, service_path: '/suggest/property' },
    },
    extend: {
      propose_properties: { service_url: baseUrl, service_path: '/extend/propose' },
      property_settings: [
        {
          name: 'maxItems',
          label: 'Maximum number of values',
          type: 'number',
          default: 1,
        },
      ],
    },
  });
});

module.exports = router;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\preview.js ====

/**
 * @swagger
 * /preview:
 *   get:
 *     summary: Example GET endpoint for preview
 *     description: Detailed description for the preview endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');

// Preview Route
// This endpoint generates a preview of an entity.
router.get('/', async (req, res) => {
  try {
    const id = req.query.id;
    if (!id) {
      return res.status(400).send('Entity ID is required.');
    }

    const userPrompt = `Generate a short HTML description for an entity with the ID "${id}". Make sure the HTML is well-formed.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const htmlContent = modelResponse.text;

    res.status(200).send(htmlContent);
  } catch (error) {
    console.error('Preview error:', error);
    res.status(500).send('Failed to generate preview.');
  }
});

module.exports = router;



==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\stream-chunk.js ====

/**
 * @swagger
 * /stream-chunk:
 *   get:
 *     summary: Example GET endpoint for stream-chunk
 *     description: Detailed description for the stream-chunk endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const path = require('path');
const fs = require('fs');

// Stream Chunk Route
// This endpoint handles real-time stream chunk matching.
router.post('/', async (req, res) => {
  try {
    const { input, fileName } = req.body;
    if (!input || !fileName) {
      return res.status(400).json({ error: 'Input text and file name are required.' });
    }

    const filePath = path.join(__dirname, '..', '..', 'data', fileName);
    if (!fs.existsSync(filePath)) {
      return res.status(404).json({ error: 'File not found.' });
    }

    const fileContent = fs.readFileSync(filePath, 'utf-8');
    const userPrompt = `Given the input chunk "${input}" and the following data:\n\n---\n${fileContent}\n---\n\nDetermine the best match from the data for the input chunk. Provide a JSON object with 'match' and 'confidence' (0-100) properties. If no match is found, set 'match' to null.`;
    const modelResponse = await getModelResponse(userPrompt, true, false);

    const result = JSON.parse(modelResponse.text);

    res.status(200).json({
      match: result.match,
      confidence: result.confidence / 100
    });
  } catch (error) {
    console.error('Stream chunk error:', error);
    res.status(500).json({ error: 'Failed to process stream chunk.' });
  }
});

module.exports = router;




==== File: C:\Users\Fred\Documents\GitHub\universal-reconciliation-service\src\routes\suggest-property.js ====

/**
 * @swagger
 * /suggest-property:
 *   get:
 *     summary: Example GET endpoint for suggest-property
 *     description: Detailed description for the suggest-property endpoint.
 *     responses:
 *       200:
 *         description: Success response.
 */
const express = require('express');
const router = express.Router();
const { getModelResponse } = require('../utils');
const { v4: uuidv4 } = require('uuid');

// Suggest Property Route
// This endpoint suggests properties based on a query.
router.get('/', async (req, res) => {
  try {
    const query = req.query.prefix;
    const type = req.query.type;
    if (!query) {
      return res.status(400).json({ error: 'Query prefix is required.' });
    }

    let userPrompt;
    if (type) {
      userPrompt = `Suggest 5 properties for a data type named "${type}" that start with "${query}". Provide the suggestions in JSON format, each with a 'name' and 'id'.`;
    } else {
      userPrompt = `Suggest 5 properties that start with "${query}" in JSON format. Each property should have a 'name' and 'id'.`;
    }
    
    const modelResponse = await getModelResponse(userPrompt, true, false);
    const suggestions = JSON.parse(modelResponse.text);

    res.status(200).json({
      result: suggestions.map(s => ({
        id: s.id || uuidv4(),
        name: s.name
      }))
    });
  } catch (error) {
    console.error('Suggest property error:', error);
    res.status(500).json({ error: 'Failed to get property suggestions.' });
  }
});

module.exports = router;





--- File: project-audit-report.txt ---
Words: 96
==== Project Audit Report - 09/02/2025 17:13:39 ====

>> Checking required directories:
  [OK] Directory exists: netlify/functions
  [OK] Directory exists: netlify/functions/routes
  [OK] Directory exists: src/routes
  [OK] Directory exists: analysis
  [OK] Directory exists: data
  [OK] Directory exists: dataset/development
  [OK] Directory exists: dataset/production
  [OK] Directory exists: dataset/special
  [OK] Directory exists: public
  [OK] Directory exists: scripts
  [OK] Directory exists: tests


>> Checking required files:
  [OK] File exists: netlify/functions/api.js
  [OK] File exists: src/swagger.js
  [OK] File exists: package.json


>> Syntax check for JS files:
Checking file: netlify/functions/api.js
Status: Syntax OK

Checking file: src/swagger.js
Status: Syntax OK

==== End of Report ====



--- File: data\sample.txt ---
Words: 15
This is a sample text file containing city names like Paris, London, and Tokyo.


--- File: README.md ---
Words: 2953
# Tutorial: Setting Up the Universal Reconciliation Service API on a Windows Machine (Local Hosting)

This tutorial outlines how to set up and run the Universal Reconciliation Service API locally on a Windows machine. The API, compliant with the OpenRefine Reconciliation API specification (v0.1), supports data reconciliation, entity suggestion, preview generation, data extension, and real-time stream chunking for pattern matching against text or JSON files. Built with Node.js and Netlify Functions, it uses the Google Gemini LLM (gemini-1.5-flash) for dynamic processing. The guide includes all necessary files, detailed setup instructions, local testing, and OpenRefine integration, tailored for Windows users.

## 1. Objectives
- **Set up the API locally**: Configure and run the API on a Windows machine.
- **Ensure OpenRefine compatibility**: Verify compliance with the OpenRefine Reconciliation API spec (v0.1).
- **Enable stream chunking**: Support real-time three-character chunk matching against files.
- **Test locally**: Validate all endpoints, including reconciliation and stream chunking.
- **Integrate with OpenRefine**: Connect the local API to OpenRefine for data reconciliation.
- **Provide reproducible setup**: Include all code and instructions for Windows-specific deployment.

## 2. Prerequisites
- **System Requirements**:
  - Windows 10 or 11 (64-bit).
  - 8GB RAM minimum, internet connection.
- **Software**:
  - **Node.js**: v20+ ([nodejs.org](https://nodejs.org/en/download)).
  - **Netlify CLI**: For local testing (`npm install -g netlify-cli`).
  - **Git**: For version control ([git-scm.com](https://git-scm.com/downloads)).
  - **OpenRefine**: v3.7+ for testing ([openrefine.org](https://openrefine.org)).
  - **Text Editor**: Visual Studio Code recommended ([code.visualstudio.com](https://code.visualstudio.com)).
  - **curl or Postman**: For API testing.
- **API Key**: Google Gemini API key from [ai.google.dev](https://ai.google.dev).
- **Sample Dataset**: A CSV file (e.g., `cities.csv`) for testing.

## 3. Project Structure
Create the following directory structure on your Windows machine:
```
C:\reconciliation-service\
 data\
    sample.txt
    sample.json
 netlify\
    functions\
       metadata.js
       reconcile.js
       suggest-entity.js
       suggest-type.js
       suggest-property.js
       preview.js
       extend-propose.js
       extend.js
       stream-chunk.js
       utils.js
 package.json
 netlify.toml
 .env.example
 .gitignore
 README.md
```

## 4. Code Files
Below are the complete code files required for the API, including all OpenRefine-compliant endpoints and the stream chunking feature.

### 4.1 `data/sample.txt`
```text
This is a sample text file containing city names like Paris, London, and Tokyo.
```

### 4.2 `data/sample.json`
```json
[
  { "city": "Paris", "country": "France" },
  { "city": "London", "country": "UK" }
]
```

### 4.3 `netlify/functions/metadata.js`
```javascript
exports.handler = async (event, context) => {
  const baseUrl = `http://${event.headers.host}`;
  return {
    statusCode: 200,
    headers: { "Access-Control-Allow-Origin": "*" },
    body: JSON.stringify({
      name: "Universal Reconciliation Service",
      identifierSpace: "http://example.com/identifiers",
      schemaSpace: "http://example.com/schemas",
      defaultTypes: [{ id: "/general", name: "General Entity" }],
      view: { url: "http://example.com/view/{{id}}" },
      preview: { url: `${baseUrl}/preview?id={{id}}`, width: 400, height: 200 },
      suggest: {
        entity: { service_url: baseUrl, service_path: "/suggest/entity" },
        type: { service_url: baseUrl, service_path: "/suggest/type" },
        property: { service_url: baseUrl, service_path: "/suggest/property" },
      },
      extend: {
        propose_properties: { service_url: baseUrl, service_path: "/extend/propose" },
        property_settings: [
          { name: "maxItems", label: "Maximum number of values", type: "number", default: 1 },
        ],
      },
    }),
  };
};
```

### 4.4 `netlify/functions/reconcile.js`
```javascript
const { callGemini, getReconcileSchema } = require('./utils');

exports.handler = async (event) => {
  try {
    const queries = JSON.parse(event.body?.queries || event.queryStringParameters?.queries || '{}');
    const callback = event.queryStringParameters?.callback;
    const results = {};

    for (const [key, query] of Object.entries(queries)) {
      const prompt = `Reconcile query: ${query.query}, Type: ${query.type || '/general'}, Limit: ${query.limit || 3}, Properties: ${JSON.stringify(query.properties || [])}`;
      const llmResponse = await callGemini(prompt, getReconcileSchema());
      results[key] = { result: llmResponse.result || [] };
    }

    const response = {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(results),
    };

    if (callback) {
      response.headers["Content-Type"] = "application/javascript";
      response.body = `${callback}(${response.body})`;
    }

    return response;
  } catch (error) {
    console.error('Reconcile error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({}),
    };
  }
};
```

### 4.5 `netlify/functions/suggest-entity.js`
```javascript
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { prefix = '', type = '' } = event.queryStringParameters;
    const prompt = `Suggest entities starting with "${prefix}" for type "${type}". Return as JSON with result array of {id, name, description}.`;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        result: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
              description: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Suggest entity error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ result: [] }),
    };
  }
};
```

### 4.6 `netlify/functions/suggest-type.js`
```javascript
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { prefix = '' } = event.queryStringParameters;
    const prompt = `Suggest types starting with "${prefix}". Return as JSON with result array of {id, name}.`;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        result: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Suggest type error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ result: [] }),
    };
  }
};
```

### 4.7 `netlify/functions/suggest-property.js`
```javascript
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { prefix = '', type = '' } = event.queryStringParameters;
    const prompt = `Suggest properties starting with "${prefix}" for type "${type}". Return as JSON with result array of {id, name}.`;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        result: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Suggest property error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ result: [] }),
    };
  }
};
```

### 4.8 `netlify/functions/preview.js`
```javascript
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { id = '' } = event.queryStringParameters;
    const prompt = `Generate a preview for entity with ID "${id}". Return as JSON with html containing the preview content.`;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: { html: { type: "string" } },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Preview error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ html: '<p>Error generating preview</p>' }),
    };
  }
};
```

### 4.9 `netlify/functions/extend-propose.js`
```javascript
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { type = '', limit = 10 } = JSON.parse(event.body || '{}');
    const prompt = `Propose properties for type "${type}", limit to ${limit}. Return as JSON with properties array of {id, name}.`;
    const llmResponse = await callGemini(prompt, {
      type: "object",
      properties: {
        properties: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              name: { type: "string" },
            },
          },
        },
      },
    });
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(llmResponse),
    };
  } catch (error) {
    console.error('Propose properties error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ properties: [] }),
    };
  }
};
```

### 4.10 `netlify/functions/extend.js`
```javascript
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { ids = [], properties = [] } = JSON.parse(event.body || '{}');
    const results = { rows: {} };

    for (const id of ids) {
      const prompt = `Extend data for entity ID "${id}" with properties: ${properties.map(p => p.id).join(', ')}. Return as JSON with values for each property as array of {str or num}.`;
      const llmResponse = await callGemini(prompt, {
        type: "object",
        properties: properties.reduce((acc, prop) => ({
          ...acc,
          [prop.id]: {
            type: "array",
            items: { type: "object", properties: { str: { type: "string" }, num: { type: "number" } } },
          },
        }), {}),
      });
      results.rows[id] = llmResponse;
    }

    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify(results),
    };
  } catch (error) {
    console.error('Extend error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ rows: {} }),
    };
  }
};
```

### 4.11 `netlify/functions/stream-chunk.js`
```javascript
const fs = require('fs').promises;
const path = require('path');
const { callGemini } = require('./utils');

exports.handler = async (event) => {
  try {
    const { input } = JSON.parse(event.body || '{}');
    if (!input) {
      return {
        statusCode: 400,
        headers: { "Access-Control-Allow-Origin": "*" },
        body: JSON.stringify({ error: 'Input required' }),
      };
    }

    const chunks = [];
    for (let i = 0; i < input.length; i += 3) {
      chunks.push(input.slice(i, i + 3));
    }

    const dataDir = path.join(__dirname, '../../data');
    const files = await fs.readdir(dataDir);
    const matches = [];

    for (const file of files) {
      if (file.endsWith('.txt') || file.endsWith('.json')) {
        const content = await fs.readFile(path.join(dataDir, file), 'utf8');
        let fileData = content;
        if (file.endsWith('.json')) {
          fileData = JSON.stringify(JSON.parse(content));
        }

        for (const chunk of chunks) {
          if (fileData.toLowerCase().includes(chunk.toLowerCase())) {
            const prompt = `Match chunk "${chunk}" in file ${file}. Return context (20 chars before/after).`;
            const llmResponse = await callGemini(prompt, {
              type: 'object',
              properties: { context: { type: 'string' } },
            });
            matches.push({
              chunk,
              file,
              context: llmResponse.context || fileData.slice(Math.max(0, fileData.indexOf(chunk) - 20), fileData.indexOf(chunk) + 23),
            });
          }
        }
      }
    }

    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ matches }),
    };
  } catch (error) {
    console.error('Stream chunk error:', error);
    return {
      statusCode: 200,
      headers: { "Access-Control-Allow-Origin": "*" },
      body: JSON.stringify({ matches: [] }),
    };
  }
};
```

### 4.12 `netlify/functions/utils.js`
```javascript
const fetch = require('node-fetch');

async function callGemini(prompt, schema) {
  const apiKey = process.env.GEMINI_API_KEY;
  const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      contents: [{ role: 'user', parts: [{ text: prompt }] }],
      generationConfig: { responseMimeType: 'application/json', responseSchema: schema },
    }),
  });

  if (!response.ok) {
    throw new Error(`API error: ${response.status}`);
  }

  const result = await response.json();
  return JSON.parse(result.candidates[0].content.parts[0].text);
}

function getReconcileSchema() {
  return {
    type: 'object',
    properties: {
      result: {
        type: 'array',
        items: {
          type: 'object',
          properties: {
            id: { type: 'string' },
            name: { type: 'string' },
            score: { type: 'number' },
            match: { type: 'boolean' },
            type: {
              type: 'array',
              items: { type: 'object', properties: { id: { type: 'string' }, name: { type: 'string' } } },
            },
          },
        },
      },
    },
  };
}

module.exports = { callGemini, getReconcileSchema };
```

### 4.13 `package.json`
```json
{
  "name": "universal-reconciliation-service",
  "version": "1.0.0",
  "description": "OpenRefine-compatible reconciliation API with stream chunking",
  "main": "index.js",
  "scripts": {
    "dev": "netlify dev"
  },
  "dependencies": {
    "body-parser": "^1.20.2",
    "dotenv": "^16.0.3",
    "node-fetch": "^2.6.7"
  },
  "devDependencies": {
    "netlify-cli": "^12.0.0"
  },
  "author": "",
  "license": "ISC"
}
```

### 4.14 `netlify.toml`
```toml
[build]
  functions = "netlify/functions"

[[redirects]]
  from = "/"
  to = "/.netlify/functions/metadata"
  status = 200
  force = true

[[redirects]]
  from = "/reconcile"
  to = "/.netlify/functions/reconcile"
  status = 200
  force = true

[[redirects]]
  from = "/suggest/entity"
  to = "/.netlify/functions/suggest-entity"
  status = 200
  force = true

[[redirects]]
  from = "/suggest/type"
  to = "/.netlify/functions/suggest-type"
  status = 200
  force = true

[[redirects]]
  from = "/suggest/property"
  to = "/.netlify/functions/suggest-property"
  status = 200
  force = true

[[redirects]]
  from = "/preview"
  to = "/.netlify/functions/preview"
  status = 200
  force = true

[[redirects]]
  from = "/extend/propose"
  to = "/.netlify/functions/extend-propose"
  status = 200
  force = true

[[redirects]]
  from = "/extend"
  to = "/.netlify/functions/extend"
  status = 200
  force = true

[[redirects]]
  from = "/stream-chunk"
  to = "/.netlify/functions/stream-chunk"
  status = 200
  force = true
```

### 4.15 `.env.example`
```text
GEMINI_API_KEY=your-gemini-api-key-here
```

### 4.16 `.gitignore`
```text
node_modules
.env
```

## 5. Setup Instructions on Windows
Follow these steps to set up and run the API locally on a Windows machine.

### 5.1 Install Prerequisites
1. **Node.js**:
   - Download the Windows installer (v20+) from [nodejs.org](https://nodejs.org/en/download).
   - Run the installer, selecting Add to PATH during setup.
   - Verify installation:
     ```cmd
     node --version
     npm --version
     ```
     Expected: `v20.x.x` and `npm v9.x.x` or higher.
2. **Netlify CLI**:
   - Open Command Prompt (cmd) or PowerShell.
   - Install globally:
     ```cmd
     npm install -g netlify-cli
     ```
   - Verify:
     ```cmd
     netlify --version
     ```
3. **Git**:
   - Download and install from [git-scm.com](https://git-scm.com/downloads).
   - Verify:
     ```cmd
     git --version
     ```
4. **OpenRefine**:
   - Download from [openrefine.org](https://openrefine.org).
   - Extract the ZIP file to `C:\OpenRefine`.
   - Run:
     ```cmd
     C:\OpenRefine\openrefine.exe
     ```
   - Access at `http://localhost:3333`.
5. **Visual Studio Code**:
   - Download and install from [code.visualstudio.com](https://code.visualstudio.com).
   - Use for editing files.
6. **Gemini API Key**:
   - Obtain from [ai.google.dev](https://ai.google.dev).
   - Copy the key for use in `.env`.

### 5.2 Create Project Directory
1. Open File Explorer and create a folder: `C:\reconciliation-service`.
2. Create the directory structure as shown in Section 3.
3. Copy or create the files from Section 4 into their respective folders:
   - Use VS Code to create/edit files.
   - For example, create `C:\reconciliation-service\data\sample.txt` and paste the content from 4.1.

### 5.3 Install Dependencies
1. Open Command Prompt or PowerShell.
2. Navigate to the project directory:
   ```cmd
   cd C:\reconciliation-service
   ```
3. Install Node.js dependencies:
   ```cmd
   npm install
   ```
   This installs `body-parser`, `dotenv`, `node-fetch`, and `netlify-cli`.

### 5.4 Configure Environment
1. Copy `.env.example` to `.env`:
   - In File Explorer, right-click `.env.example` > Copy, then Paste and rename to `.env`.
   - Or use Command Prompt:
     ```cmd
     copy .env.example .env
     ```
2. Open `.env` in VS Code or Notepad.
3. Add your Gemini API key:
   ```text
   GEMINI_API_KEY=your-gemini-api-key-here
   ```
4. Save the file.

### 5.5 Run the API Locally
1. In Command Prompt or PowerShell, navigate to `C:\reconciliation-service`.
2. Start the Netlify development server:
   ```cmd
   npm run dev
   ```
   - This runs `netlify dev`, starting the API at `http://localhost:8888`.
   - Netlify CLI simulates the serverless environment locally.
3. Keep the terminal open to maintain the server.

### 5.6 Test the API
1. **Verify Metadata Endpoint**:
   - Open a new Command Prompt or use curl in PowerShell:
     ```cmd
     curl http://localhost:8888/
     ```
   - Expected response:
     ```json
     {
       "name": "Universal Reconciliation Service",
       "identifierSpace": "http://example.com/identifiers",
       "schemaSpace": "http://example.com/schemas",
       "defaultTypes": [{"id": "/general", "name": "General Entity"}],
       ...
     }
     ```
2. **Test Reconciliation**:
   ```cmd
   curl -X POST http://localhost:8888/reconcile -d "queries={\"q0\":{\"query\":\"Paris\",\"type\":\"/location\"}}"
   ```
   - Expected:
     ```json
     {
       "q0": {
         "result": [{"id": "paris-fr", "name": "Paris, France", "score": 0.95, "match": true, "type": [{"id": "/location", "name": "Location"}]}]
       }
     }
     ```
3. **Test Stream Chunking**:
   ```cmd
   curl -X POST http://localhost:8888/stream-chunk -d "{\"input\":\"paris\"}"
   ```
   - Expected:
     ```json
     {
       "matches": [
         {"chunk": "par", "file": "sample.txt", "context": "...city of paris is..."}
       ]
     }
     ```
4. **Use Postman (Optional)**:
   - Create a POST request to `http://localhost:8888/reconcile` with body:
     ```json
     {"queries": {"q0": {"query": "Paris", "type": "/location"}}}
     ```
   - Verify similar responses.

### 5.7 Integrate with OpenRefine
1. **Launch OpenRefine**:
   ```cmd
   C:\OpenRefine\openrefine.exe
   ```
   Access at `http://localhost:3333`.
2. **Create Project**:
   - Click **Create Project** > **Choose Files**.
   - Upload a CSV (e.g., `cities.csv`):
     ```csv
     name
     Paris
     London
     Tokyo
     ```
   - Configure parsing (comma delimiter, UTF-8) and create the project.
3. **Add Reconciliation Service**:
   - Select the `name` column.
   - Click **Reconcile** > **Start reconciling**.
   - Click **Add Standard Service**.
   - Enter `http://localhost:8888/`.
   - OpenRefine fetches metadata, displaying Universal Reconciliation Service.
   - Click **Add Service**.
4. **Reconcile**:
   - Select the service and type (e.g., `/location`).
   - Click **Start Reconciling**.
   - Review matches (e.g., `Paris -> Paris, France, score: 0.95`).
5. **Extend Data (Optional)**:
   - After reconciliation, go to `name` > **Reconcile** > **Add column based on this column**.
   - Select properties (e.g., `population`) via `/extend/propose`.
   - Values appear in a new column (e.g., `2148000` for Paris).

### 5.8 Verify OpenRefine Compliance
- **Testbench**:
  - Visit [reconciliation-api.github.io/testbench](https://reconciliation-api.github.io/testbench/).
  - Enter `http://localhost:8888/`.
  - Run tests for metadata, reconcile, suggest, preview, and extend.
  - Ensure all pass to confirm OpenRefine spec (v0.1) compliance.
- **Streaming**:
  - Test with a larger CSV (e.g., 100 rows). OpenRefine batches queries (1050 rows per `/reconcile` POST).
  - Check OpenRefine logs (`http://localhost:3333/logs`) for errors.

## 6. Troubleshooting
- **Node.js Errors**:
  - If `npm install` fails, ensure Node.js is added to PATH. Reinstall or run `npm cache clean --force`.
- **Netlify CLI Fails**:
  - Verify installation: `netlify --version`.
  - Update: `npm install -g netlify-cli@latest`.
- **API Not Responding**:
  - Check `.env` for correct `GEMINI_API_KEY`.
  - Test Gemini API connectivity:
    ```cmd
    curl https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=your-gemini-api-key
    ```
  - Ensure `netlify dev` is running.
- **OpenRefine Connection Issues**:
  - Confirm `http://localhost:8888/` returns metadata.
  - Check firewall settings (allow port 8888).
- **Stream Chunking Errors**:
  - Verify `/data` folder exists with `sample.txt` and `sample.json`.
  - Check file permissions in Windows (right-click > Properties > Security).
- **Performance**:
  - Gemini API latency is ~100500ms. If slow, verify internet connection or API key quotas.

## 7. OpenRefine Compliance
The API fully implements the OpenRefine Reconciliation API spec (v0.1):
- **Metadata** (`/`): Service details, suggest/extend configs.
- **Reconcile** (`/reconcile`): Batch queries, type constraints, properties, JSONP.
- **Suggest** (`/suggest/entity`, `/suggest/type`, `/suggest/property`): Prefix-based filtering.
- **Preview** (`/preview`): HTML snippets.
- **Extend** (`/extend/propose`, `/extend`): Property proposals and data fetching.
- **Streaming**: Batched POSTs for large datasets.
- **JSONP**: Supports `callback` for cross-origin requests.

## 8. Example Workflow
1. **Setup**:
   - Create `cities.csv` and place in `C:\reconciliation-service`.
   - Run `npm run dev`.
2. **Reconcile**:
   - In OpenRefine, add `http://localhost:8888/` as a service.
   - Reconcile `name` column with `/location` type.
   - Matches: `Paris -> Paris, France (score: 0.95)`.
3. **Extend**:
   - Add `population` property.
   - Result: New column with `2148000` for Paris.
4. **Stream Chunking**:
   ```cmd
   curl -X POST http://localhost:8888/stream-chunk -d "{\"input\":\"paris\"}"
   ```
   Expected:
   ```json
   {
     "matches": [
       {"chunk": "par", "file": "sample.txt", "context": "...city of paris is..."}
     ]
   }
   ```

## 9. Conclusion
This tutorial provides a complete guide to setting up the Universal Reconciliation Service API on a Windows machine for local hosting. The API is fully compliant with OpenRefine, supports real-time stream chunking, and leverages Gemini LLM for dynamic processing. By following the steps, you can run the API locally, test all endpoints, and integrate with OpenRefine for data reconciliation. For production use, consider deploying to Netlify and adding caching or external storage for scalability.

